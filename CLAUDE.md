# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Airport emergency response intelligent agent system that combines **ReAct Agent** with **FSM (Finite State Machine) validation** for handling airport apron incidents like fuel spills and bird strikes. The system uses LLM-driven reasoning while ensuring compliance through deterministic validation layers.

## Development Commands

```bash
# Install dependencies
pip install -e ".[dev,llm]"

# Run tests (all tests are in tests/ directory)
pytest tests/ -v

# Run single test file
pytest tests/integration/test_integration.py -v

# Run specific test class/method
pytest tests/integration/test_integration.py::TestRiskAssessment::test_high_risk_fuel_engine_running -v

# Run demo scripts (in demos/ directory)
python demos/demo_position_impact.py           # Position impact analysis demo
python demos/demo_flight_impact.py             # Flight impact prediction demo

# Run interactive mode (requires LLM API key)
python apps/run_agent.py

# Start API server
python -m apps.api.main
# Or: uvicorn apps.api.main:app --reload

# Linting
black . --line-length 100
isort .
mypy .
```

## Project Structure

```
airport-emergency-agent/
â”œâ”€â”€ agent/           # Core agent (ReAct + FSM)
â”‚   â”œâ”€â”€ graph.py     # LangGraph state machine
â”‚   â”œâ”€â”€ state.py     # AgentState TypedDict
â”‚   â””â”€â”€ nodes/       # Graph nodes (reasoning, tool_executor, etc.)
â”œâ”€â”€ tools/           # Tool system
â”‚   â”œâ”€â”€ registry.py  # Tool registration
â”‚   â”œâ”€â”€ base.py      # BaseTool class
â”‚   â”œâ”€â”€ information/ # Info query tools
â”‚   â”œâ”€â”€ spatial/     # Topology analysis tools
â”‚   â”œâ”€â”€ knowledge/   # RAG knowledge retrieval
â”‚   â”œâ”€â”€ assessment/  # Risk assessment
â”‚   â””â”€â”€ action/      # Action tools (notify, report)
â”œâ”€â”€ tests/           # Test files (pytest auto-discovery)
â”œâ”€â”€ demos/           # Demo scripts
â”œâ”€â”€ docs/            # Documentation and design docs
â”œâ”€â”€ scenarios/       # Scenario configurations (prompt.yaml)
â”œâ”€â”€ constraints/     # Constraint definitions
â”œâ”€â”€ fsm/             # Finite State Machine definitions
â”œâ”€â”€ apps/            # Entry points (CLI + API)
â”œâ”€â”€ config/          # Configuration files
â”œâ”€â”€ data/            # Data files
â”œâ”€â”€ outputs/         # Generated reports
â”œâ”€â”€ scripts/         # Data processing scripts (offline)
â”œâ”€â”€ Radiotelephony_ATC.json  # Aviation radio telephony normalization rules
â””â”€â”€ BSRC.json        # Bird strike risk classification rules
```

## Environment Setup

Copy `.env.example` to `.env` and configure:
- `LLM_PROVIDER`: `zhipu` or `openai`
- `LLM_MODEL`: Model name (e.g., `glm-4`)
- `LLM_API_KEY`: Your API key

## Architecture

### Hybrid Design: ReAct + FSM

```
User Input â†’ Input Parser â†’ ReAct Reasoning Loop â†’ FSM Validation â†’ Output Report
                                    â†“
                              Tool Execution
                         (deterministic engines)
```

**Key principle**: LLM handles flexible reasoning and decision-making, while deterministic components (rule engine, graph algorithms) handle calculations that require precision.

## Detailed Data Flow

### User Input â†’ Entity Extraction Flow

```python
# agent/nodes/input_parser.py

User Input (Chinese text)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. normalize_radiotelephony_text()                  â”‚
â”‚    åŸºç¡€è§„èŒƒåŒ–: æ´â†’0, å¹ºâ†’1, æ‹â†’7                      â”‚
â”‚    è·‘é“æ–¹å‘æ ‡è¯†: è·‘é“27å·¦â†’è·‘é“27L (ICAOæ ¼å¼)         â”‚
â”‚    ä» Radiotelephony_ATC.json åŠ è½½è§„åˆ™              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RadiotelephonyNormalizer (LLM + è§„åˆ™æ£€ç´¢)         â”‚
â”‚    â”œâ”€ retrieve_examples()                           â”‚
â”‚    â”‚  # å…³é”®è¯åŒ¹é…æ£€ç´¢ Few-shot ç¤ºä¾‹                 â”‚
â”‚    â”‚  # æå–: runway, taxiway, stand, flight        â”‚
â”‚    â”œâ”€ _build_prompt()                               â”‚
â”‚    â”‚  # æ„å»º Few-shot æç¤ºè¯                         â”‚
â”‚    â”œâ”€ LLM.invoke()                                  â”‚
â”‚    â”‚  # è¯­ä¹‰è§„èŒƒåŒ– (5ç§’è¶…æ—¶)                         â”‚
â”‚    â””â”€ è¿”å› {                                        â”‚
â”‚          normalized_text,                           â”‚
â”‚          entities {flight_no, position, ...},       â”‚
â”‚          confidence                                 â”‚
â”‚       }                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
identify_scenario()
    # Match keywords against ScenarioRegistry
    # Returns: "oil_spill", "bird_strike", etc.
    â†“
extract_entities_hybrid()
    â”œâ”€ Fast path: Regex patterns
    â”‚  # Extracts: position, fluid_type, engine_status, flight_no
    â”‚  # Bird strike adds: event_type, affected_part, current_status,
    â”‚  # phase, evidence, bird_info, ops_impact (from manifest regex)
    â”‚  # Patterns: r'[A-Z]{2,3}\d{3,4}', r'(ç‡ƒæ²¹|æ»‘æ²¹|æ¶²å‹æ²¹)', etc.
    â”œâ”€ Flex path: LLM semantic extraction
    â”‚  # Handles ambiguous natural language
    â”‚  # Example: "å³ä¾§å‘åŠ¨æœºæ¼æ²¹" â†’ {side: "right", fluid_type: "OIL"}
    â””â”€ Merge: Normalizer entities > Regex > LLM
    â†“
Optional: understand_conversation() [if ENABLE_SEMANTIC_UNDERSTANDING=true]
    â”œâ”€ Extract facts from conversation context
    â”œâ”€ Confidence scoring per entity
    â”œâ”€ Split into accepted/low-confidence
    â””â”€ Detect semantic issues (conflicts, ambiguities)
    â†“
apply_auto_enrichment()  # ğŸ”„ Parallel execution
    â”œâ”€ Phase 1: Independent queries (ThreadPoolExecutor, max 3 workers)
    â”‚  â”œâ”€ get_aircraft_info(flight_no) â†’ aircraft details
    â”‚  â”œâ”€ flight_plan_lookup(flight_no) â†’ flight schedule
    â”‚  â””â”€ get_stand_location(position) â†’ stand coordinates + topology
    â”‚
    â”œâ”€ Phase 2: Dependent calculations (requires Phase 1 results)
    â”‚  â”œâ”€ calculate_impact_zone(position, fluid_type, risk_level)
    â”‚  â”‚  # BFS graph diffusion algorithm
    â”‚  â”‚  # Rules: FUEL HIGH=3 hops, MEDIUM=2 hops, etc.
    â”‚  â””â”€ analyze_position_impact(position)
    â”‚     # Direct impact analysis + adjacent facilities
    â”‚
    â””â”€ Timeout handling: 10s per future, graceful degradation
    â†“
update_checklist()
    # Mark collected fields as complete in state.checklist
    â†“
Output: Updated AgentState
    â”œâ”€ incident: enriched with auto-fetched data
    â”œâ”€ checklist: {fluid_type: true, position: true, ...}
    â”œâ”€ spatial_analysis: {affected_taxiways, affected_runways, ...}
    â”œâ”€ flight_plan_table: flight schedule data
    â””â”€ observations: enrichment process records

### Bird Strike Checklist Fields

Bird strike adds P2 fields for risk assessment accuracy:
- `phase` (flight phase)
- `evidence` (evidence strength)
- `bird_info` (bird characteristics)
- `ops_impact` (operational impact)

See `scenarios/bird_strike/checklist.yaml` and `docs/SCENARIO_FIELD_CONTRACTS.md`.

### Bird Strike Risk Assessment (BSRC)

```python
# tools/assessment/assess_bird_strike_risk.py

incident (phase, affected_part, event_type, current_status, crew_request, ...)
    â†“
assess_bird_strike_risk.execute()
    â”œâ”€ Normalize inputs: phase/impact_area/evidence/bird_info/ops_impact
    â”œâ”€ Weighted score + rule boosts (BSRC.json)
    â”œâ”€ Apply risk floor overrides (R1-R4)
    â””â”€ Update state.risk_assessment + mandatory_actions_done.risk_assessed
```
```

### Risk Assessment â†’ Spatial Analysis Flow

```python
# tools/assessment/assess_risk.py

Current incident (fluid_type, engine_status, continuous, leak_size)
    â†“
assess_risk_tool.execute()
    â”œâ”€ Load rules from scenario or defaults
    â”œâ”€ Match against RISK_RULES (priority-ordered, 12 rules):
    â”‚  1. (FUEL + continuous + RUNNING) â†’ HIGH (95 pts)
    â”‚  2. (FUEL + RUNNING) â†’ HIGH (90 pts)
    â”‚  3. (FUEL + continuous) â†’ HIGH (85 pts)
    â”‚  ...
    â”‚  12. (OIL) â†’ LOW (25 pts)
    â”‚
    â”œâ”€ Return: {level, score, factors, immediate_actions}
    â”‚  # level: "HIGH", "MEDIUM_HIGH", "MEDIUM", "LOW"
    â”‚  # score: 0-100 numerical score
    â”‚  # factors: ["èˆªç©ºç‡ƒæ²¹", "å‘åŠ¨æœºè¿è½¬", ...]
    â”‚  # immediate_actions: ["å…³é—­å‘åŠ¨æœº", "æ³¡æ²«è¦†ç›–", ...]
    â”‚
    â””â”€ Update state.risk_assessment
    â†“
calculate_impact_zone_tool.execute()
    â”œâ”€ Load airport topology (NetworkX graph from JSON)
    â”‚  # Nodes: stands, taxiways, runways with lat/lon
    â”‚  # Edges: connectivity between nodes
    â”‚
    â”œâ”€ Find start node (nearest to position)
    â”‚
    â”œâ”€ Look up spread rule from SPREAD_RULES
    â”‚  FUEL:
    â”‚    HIGH: radius=3, runway_impact=true
    â”‚    MEDIUM: radius=2, runway_impact=true
    â”‚    LOW: radius=1, runway_impact=false
    â”‚  HYDRAULIC: radius=2/1/1, no runway
    â”‚  OIL: radius=1/1/0
    â”‚
    â”œâ”€ BFS spread from start node (breadth-first search)
    â”‚  # Explore graph up to radius hops
    â”‚
    â”œâ”€ Classify nodes: taxiway | runway | stand
    â”‚
    â”œâ”€ Check runway adjacency (if rule.runway_impact)
    â”‚
    â””â”€ Return: {isolated_nodes, affected_taxiways, affected_runways}
    â†“
analyze_position_impact_tool.execute()
    â”œâ”€ Analyze direct impact on facility
    â”œâ”€ Estimate closure time (based on fluid type + risk level)
    â”œâ”€ Calculate severity score (1-10)
    â””â”€ Identify adjacent affected facilities
    â†“
predict_flight_impact_tool.execute() [âš ï¸ Partially implemented]
    â”œâ”€ Query flight plan database
    â”œâ”€ Match flights to affected stands/runways/taxiways
    â”œâ”€ Calculate delay predictions
    â””â”€ Generate severity distribution
```

### FSM Validation â†’ Mandatory Actions Flow

```python
# agent/nodes/fsm_validator.py

AgentState (after critical tool execution: assess_risk, calculate_impact_zone, notify_department)
    â†“
fsm_validator_node()
    â”œâ”€ Get validator: FSMValidator(FSMEngine)
    â”‚
    â”œâ”€ Call validate(agent_state):
    â”‚  â”œâ”€ sync_with_agent_state()
    â”‚  â”‚  # Infer current FSM state from Agent completion
    â”‚  â”‚  # Example: checklist.p1_complete=true â†’ P1_RISK_ASSESS
    â”‚  â”‚            mandatory.risk_assessed=true â†’ P2_IMMEDIATE_CONTROL
    â”‚  â”‚
    â”‚  â”œâ”€ check_preconditions(target_state, agent_state)
    â”‚  â”‚  # For each precondition (e.g., "checklist.fluid_type"):
    â”‚  â”‚  #   Check if satisfied; add error if not
    â”‚  â”‚  # Example: Entering P2 requires mandatory.risk_assessed=true
    â”‚  â”‚
    â”‚  â””â”€ check_mandatory_actions(agent_state)
    â”‚     â”œâ”€ For each MandatoryAction:
    â”‚     â”‚  â”œâ”€ Evaluate condition (e.g., risk_level == "HIGH")
    â”‚     â”‚  â”œâ”€ If triggered: check if completed
    â”‚     â”‚  â””â”€ If not completed: add to pending_actions
    â”‚     â”‚
    â”‚     # Example:
    â”‚     # Condition: risk_level == "HIGH"
    â”‚     # Action: notify_department(department: æ¶ˆé˜², priority: immediate)
    â”‚     # Check field: fire_dept_notified
    â”‚     #
    â”‚     â””â”€ Return (errors, pending_actions)
    â”‚
    â””â”€ Return: FSMValidationResult
       â”œâ”€ is_valid: boolean
       â”œâ”€ current_state: FSM state before validation
       â”œâ”€ inferred_state: FSM state after validation
       â”œâ”€ errors: ["è¿›å…¥P2éœ€è¦å…ˆå®Œæˆrisk_assessed", ...]
       â””â”€ pending_actions: [{action: "notify_department", params: {...}}, ...]
    â†“
Routing decision (after_fsm_validation):
    â”œâ”€ If errors: â†’ reasoning (Agent needs to fix)
    â”‚  # FSM error messages guide Agent remediation
    â”‚  # Example: "é«˜å±æƒ…å†µå¿…é¡»é€šçŸ¥æ¶ˆé˜²" â†’ Agent calls notify_department
    â”‚
    â”œâ”€ If COMPLETED state: â†’ output_generator
    â”‚
    â”œâ”€ If P8_CLOSE + pending_actions: â†’ reasoning (trigger forced actions)
    â”‚
    â””â”€ Otherwise: â†’ reasoning (continue)
```

### Report Generation â†’ Final Output Flow

```python
# agent/nodes/output_generator.py

Complete AgentState
    â†“
output_generator_node()
    â”œâ”€ Build affected areas text (from spatial_analysis)
    â”‚  # Format: "501æœºä½ã€æ»‘è¡Œé“A1/A2ã€è·‘é“09"
    â”‚
    â”œâ”€ Build event context
    â”‚  â”œâ”€ incident: position, fluid_type, engine_status, continuous
    â”‚  â”œâ”€ risk_assessment: level, score, factors
    â”‚  â””â”€ spatial_analysis: impact zone, affected facilities
    â”‚
    â”œâ”€ Collect handling process (from actions_taken)
    â”‚  # Timeline of tool executions with timestamps
    â”‚  # Example: [
    â”‚  #   "14:30 - é£é™©è¯„ä¼°ï¼šHIGHçº§é£é™©ï¼ˆ90åˆ†ï¼‰",
    â”‚  #   "14:32 - é€šçŸ¥æ¶ˆé˜²éƒ¨é—¨ï¼šå·²åˆ°è¾¾ç°åœº",
    â”‚  #   ...
    â”‚  # ]
    â”‚
    â”œâ”€ Collect notifications sent
    â”‚  # List of notified departments with priority
    â”‚
    â”œâ”€ Prepare recommendations (based on risk level)
    â”‚  # HIGH: "ç«‹å³å…³é—­å‘åŠ¨æœº", "æ³¡æ²«è¦†ç›–", ...
    â”‚  # MEDIUM: "æ¸…æ±¡äººå‘˜å°±ä½", "é˜²æ»‘å¤„ç†", ...
    â”‚
    â”œâ”€ Call LLM to generate summary (optional)
    â”‚  # Narrative summary of incident handling
    â”‚
    â”œâ”€ Render final report from template [âš ï¸ Currently: 778-line string concatenation]
    â”‚  # Report structure:
    â”‚  #   - Title, event summary, risk level
    â”‚  #   - Handling process (timeline of actions)
    â”‚  #   - Checklist items (P1/P2 fields)
    â”‚  #   - Coordination units notified
    â”‚  #   - Operational impact (affected flights, closure time)
    â”‚  #   - Recommendations (safety measures, follow-up)
    â”‚  #   - Timestamp
    â”‚
    â””â”€ Return: final_report (dict) + final_answer (str)
    â†“
tool_executor_node() [if generate_report action]
    â”œâ”€ Detect report_generated flag
    â”œâ”€ Call output_generator_node()
    â”œâ”€ Set awaiting_user = True
    â”œâ”€ Set next_node = "end"
    â””â”€ Wait for user confirmation
```

### Core Components

**LangGraph State Machine** (`agent/graph.py`):
- Defines the agent workflow as a directed graph
- Entry: `input_parser` â†’ `reasoning` â†’ conditional routing
- Key routing functions: `should_continue()`, `after_tool_execution()`, `after_fsm_validation()`

**Agent State** (`agent/state.py`):
- `AgentState` TypedDict containing: incident info, checklist status, FSM state, risk assessment, spatial analysis
- `FSMState` enum: INIT â†’ P1_RISK_ASSESS â†’ P2_IMMEDIATE_CONTROL â†’ ... â†’ P8_CLOSE â†’ COMPLETED
- `create_initial_state()` factory function

**Node Implementations** (`agent/nodes/`):
- `input_parser.py`: Entity extraction from Chinese text (position, fluid type, engine status). Implements **two-stage radiotelephony normalization**:
  1. Basic rule-based conversion (æ´â†’0, å¹ºâ†’1, æ‹â†’7)
  2. LLM + rule-based Few-shot retrieval (not vector RAG)
  Automatically retrieves flight info from `data/raw/èˆªç­è®¡åˆ’/Log_*.txt` and performs topology analysis from `scripts/data_processing/topology_clustering_based.json`.
- `reasoning.py`: ReAct loop with `build_scenario_prompt()` for dynamic prompt loading. Displays flight information (airline, stand, runway, flight type) and topology analysis results (impact zone, affected taxiways/runways) in context summary.
- `tool_executor.py`: Executes tools from registry
- `fsm_validator.py`: Validates state transitions and mandatory actions
- `output_generator.py`: Generates final reports

### Scenario-Specific Prompts

**Dynamic Prompt Loading** (`scenarios/base.py`, `agent/nodes/reasoning.py`):
- Each scenario has `prompt.yaml` defining its system prompt and field collection order
- `build_scenario_prompt()` function dynamically loads scenario configuration
- `ScenarioRegistry` manages scenario registration and retrieval
- Fields are collected in the order defined by `field_order` in each scenario's prompt.yaml

**Prompt Configuration** (`scenarios/<scenario>/prompt.yaml`):
```yaml
system_prompt: |
  ä½ æ˜¯æœºåœºæœºåªåº”æ€¥å“åº”ä¸“å®¶ Agent...

field_order:           # ä¿¡æ¯æ”¶é›†é¡ºåºï¼ˆå¼ºåˆ¶æŒ‰åºè¯¢é—®ï¼‰
  - flight_no
  - position
  - fluid_type
  - engine_status
  - continuous

field_names:           # å­—æ®µä¸­æ–‡åç§°æ˜ å°„
  flight_no: èˆªç­å·
  position: äº‹å‘ä½ç½®

ask_prompts:           # å„å­—æ®µçš„è¿½é—®æç¤º
  flight_no: "è¯·æä¾›æ¶‰äº‹é£æœºçš„èˆªç­å·ï¼Ÿ"
  position: "è¯·æŠ¥å‘Šäº‹ä»¶å‘ç”Ÿçš„å…·ä½“ä½ç½®ï¼Ÿ"
```

### Tool System

**Tool Registry** (`tools/registry.py`):
- Tools registered with scenario tags (e.g., `["oil_spill", "common"]`)
- `ToolRegistry.get_by_scenario()` returns scenario-specific tools

**Tool Categories**:
- `information/`: `ask_for_detail`, `get_aircraft_info` (automatically called when flight number is detected), `radiotelephony_normalizer` (ATC phonetic normalization)
- `spatial/`: `get_stand_location`, `calculate_impact_zone` (graph-based BFS diffusion, automatically called when position is detected)
- `knowledge/`: `search_regulations` (RAG-style retrieval)
- `assessment/`: `assess_risk` (rule-based deterministic scoring)
- `action/`: `notify_department`, `generate_report`

**Knowledge Base** (`tools/knowledge/search_regulations.py`):
- Mock knowledge base with emergency procedures for fuel, hydraulic, and engine oil spills
- Each regulation includes: risk level, risk features, cleanup method, source
- Report generator references retrieved knowledge when generating reports

**Creating New Tools**: Extend `BaseTool` from `tools/base.py`, implement `execute(state, inputs)` method, register in `tools/registry.py`.

### Risk Assessment Rules

**Fluid Type Risk Matrix** (`tools/assessment/assess_risk.py`):
| Fluid Type | Risk Level | Key Features | Cleanup Method |
|------------|------------|--------------|----------------|
| Aviation Fuel (FUEL) | HIGH | Flammable/explosive, foam coverage required | Absorbent materials + explosion-proof pump |
| Hydraulic Oil | MEDIUM-HIGH | Flammable, high-pressure jet hazard | Pressure relief first, then absorbent |
| Engine Oil (OIL) | MEDIUM | Combustible, toxic smoke | Absorbent materials + industrial cleaner |

**Immediate Actions by Risk Level**:
- HIGH: Notify fire department, shut down engine, evacuate, establish safety zone, foam coverage
- MEDIUM-HIGH: Fire department on standby, pressure relief, set up warning zone
- MEDIUM: Standby resources, absorbent materials, anti-slip treatment
- LOW: Maintenance notification, monitoring

### Constraint System

**Checklist** (`agent/state.py`):
- P1 fields (must collect): fluid_type, continuous, engine_status, position
- P2 fields: leak_size

**Mandatory Actions**:
- `risk_assessed`: Must be done before proceeding
- `fire_dept_notified`: Required for HIGH risk
- `atc_notified`: Required for certain scenarios

**FSM Validation** triggers after critical tool executions: `assess_risk`, `calculate_impact_zone`, `notify_department`

### Topology Analysis

**Airport Topology Graph** (`tools/spatial/topology_loader.py`):
- Loaded from `scripts/data_processing/topology_clustering_based.json` (generated from trajectory clustering)
- Nodes: stands, taxiways, runways with lat/lon coordinates
- Edges: connectivity between nodes (undirected graph)
- BFS-based reachability analysis for impact zone calculation

**Automatic Analysis** (`agent/nodes/input_parser.py`):
- When position is extracted â†’ `get_stand_location` called automatically
- Location details: coordinates, adjacent taxiways, nearest runway
- Impact zone calculation: BFS diffusion based on fluid type and risk level
- Results stored in `spatial_analysis` and `incident.impact_zone`

**Impact Zone Rules** (`tools/spatial/calculate_impact_zone.py`):
| Fluid Type | Risk Level | BFS Radius | Runway Impact |
|------------|------------|------------|---------------|
| FUEL | HIGH | 3 hops | Yes |
| FUEL | MEDIUM | 2 hops | Yes |
| FUEL | LOW | 1 hop | No |
| HYDRAULIC | HIGH/MEDIUM | 2 hops | No |
| OIL | HIGH/MEDIUM | 1 hop | No |

### Radiotelephony Normalization

**Overview**: Converts aviation radio telephony (ATC phonetic alphabet) to standard format using a two-stage approach.

**Implementation** (`tools/information/radiotelephony_normalizer.py`):

```python
# Stage 1: Basic rule-based normalization (agent/nodes/input_parser.py:135-175)
def normalize_radiotelephony_text(text: str) -> str:
    """
    åŸºç¡€è§„èŒƒåŒ–: æ•°å­—å’Œå­—æ¯è¯»æ³•è½¬æ¢
    - æ´â†’0, å¹ºâ†’1, ä¸¤â†’2, ä¸‰â†’3, æ‹â†’7, å…«â†’8, ä¹â†’9
    - é˜¿å°”æ³•â†’A, å¸ƒæ‹‰æ²ƒâ†’B, æŸ¥ç†â†’C
    - è§„èŒƒåŒ–ä½ç½®é¡ºåº: "12æ»‘è¡Œé“" â†’ "æ»‘è¡Œé“12"
    - è·‘é“æ–¹å‘æ ‡è¯†è½¬æ¢: "è·‘é“27å·¦" â†’ "è·‘é“27L" (ICAOæ ¼å¼)
      # é¿å…"è·‘é“27å·¦å‘ç”Ÿé¸Ÿå‡»"è¢«è¯¯è§£æä¸º"è·‘é“27"+"å·¦å‘"
    """
    # ä» Radiotelephony_ATC.json åŠ è½½è§„åˆ™
    digits_map = {"æ´": "0", "å¹º": "1", "æ‹": "7", ...}
    letters_map = {"é˜¿å°”æ³•": "A", "å¸ƒæ‹‰æ²ƒ": "B", ...}
    # ... æ‰§è¡Œæ›¿æ¢

    # è·‘é“æ–¹å‘æ ‡è¯†è½¬æ¢ (å·¦â†’L, å³â†’R, ä¸­â†’C)
    normalized = re.sub(
        r"(è·‘é“\d{1,2})(å·¦|å³|ä¸­)",
        lambda m: f"{m.group(1)}{'L' if m.group(2) == 'å·¦' else 'R' if m.group(2) == 'å³' else 'C'}",
        normalized,
    )
```

```python
# Stage 2: LLM + Rule-based Few-shot retrieval (tools/information/radiotelephony_normalizer.py:31-238)
class RadiotelephonyNormalizer:
    """
    èˆªç©ºè¯»æ³•è§„èŒƒåŒ–å¼•æ“ (LLM + è§„åˆ™æ£€ç´¢ï¼Œéå‘é‡ RAG)

    å·¥ä½œæµç¨‹:
    1. retrieve_examples(input_text)
       - å…³é”®è¯åŒ¹é…: æå– runway/taxiway/stand/flight/oil_spill/bird_strike
       - è§„åˆ™ç›¸ä¼¼åº¦: åŸºäºå…³é”®è¯é‡å åº¦æ‰“åˆ† (éå‘é‡ç›¸ä¼¼åº¦)
       - è¿”å› top-3 æœ€ç›¸ä¼¼ç¤ºä¾‹

    2. _build_prompt(text, examples)
       - åŠ è½½è½¬æ¢è§„åˆ™ä» Radiotelephony_ATC.json
       - æ„å»º Few-shot æç¤ºè¯

    3. normalize_with_llm(text, timeout=5)
       - è°ƒç”¨ LLM è¿›è¡Œè¯­ä¹‰è§„èŒƒåŒ–
       - è¿”å›æ ‡å‡†åŒ–å®ä½“å’Œç½®ä¿¡åº¦

    æ³¨æ„: å½“å‰å®ç°ä½¿ç”¨å…³é”®è¯åŒ¹é…ï¼Œä¸æ˜¯çœŸæ­£çš„å‘é‡ RAG
    """

    def retrieve_examples(self, input_text: str, top_k: int = 3):
        """æ£€ç´¢æœ€ç›¸ä¼¼çš„è§„èŒƒåŒ–ç¤ºä¾‹ (åŸºäºå…³é”®è¯ï¼Œéå‘é‡)"""
        keywords = self._extract_keywords(input_text)
        # å…³é”®è¯: ["runway", "taxiway", "stand", "flight", "oil_spill", "bird_strike"]

        for example in examples:
            score = self._calculate_similarity(keywords, example["input"])
            # è§„åˆ™æ‰“åˆ†: å…³é”®è¯å‘½ä¸­ +1 åˆ†
        return top_k_examples

    def normalize_with_llm(self, text: str, timeout: int = 5):
        """ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰è§„èŒƒåŒ–"""
        examples = self.retrieve_examples(text, top_k=3)
        prompt = self._build_prompt(text, examples)

        response = self.llm.invoke(prompt, timeout=timeout)
        result = self._parse_llm_response(response.content)

        return {
            "normalized_text": "å·èˆª3U3177 è·‘é“02L æŠ¥å‘Šé¸Ÿå‡»",
            "entities": {
                "flight_no": "3U3177",
                "position": "02L",
                "event_type": "bird_strike"
            },
            "confidence": 0.95
        }
```

**Knowledge Base** (`Radiotelephony_ATC.json`):

```json
{
  "digits": {
    "0": "æ´", "1": "å¹º", "2": "ä¸¤", "7": "æ‹", ...
  },
  "letters": {
    "A": "é˜¿å°”æ³•", "B": "å¸ƒæ‹‰æ²ƒ", "C": "æŸ¥ç†", ...
  },
  "normalization_rules": {
    "runway_formats": {
      "examples": [
        {"input": "è·‘é“æ´ä¸¤å·¦", "output": "02L"},
        {"input": "è·‘é“å¹ºå…«å³", "output": "18R"}
      ]
    },
    "flight_formats": {
      "airline_codes": {
        "å·èˆª": "3U", "å›½èˆª": "CA", "ä¸œèˆª": "MU", ...
      }
    }
  }
}
```

**Integration in Input Parser** (`agent/nodes/input_parser.py:570-586`):

```python
# æ­¥éª¤ 1: åŸºç¡€è§„èŒƒåŒ–
normalized_message = normalize_radiotelephony_text(user_message)
# "å·èˆªä¸‰å¹ºæ‹æ‹ è·‘é“æ´ä¸¤å·¦" â†’ "å·èˆª3U3177 è·‘é“02L"

# æ­¥éª¤ 2: LLM + è§„åˆ™æ·±åº¦è§„èŒƒåŒ–
normalizer = RadiotelephonyNormalizerTool()
normalization_result = normalizer.execute(state, {"text": normalized_message})
enhanced_message = normalization_result["normalized_text"]
pre_extracted_entities = normalization_result["entities"]
# {
#   "flight_no": "3U3177",
#   "position": "02L",
#   "event_type": "bird_strike"
# }

# æ­¥éª¤ 3: åˆå¹¶åˆ°å®ä½“æå–ç»“æœ
extracted = extract_entities_hybrid(enhanced_message, history, scenario_type)
extracted.update(pre_extracted_entities)  # Normalizer entities ä¼˜å…ˆçº§æœ€é«˜
```

**Design Notes**:

- **Current Implementation**: Rule-based keyword matching (not vector RAG)
  - âœ… Fast, no external dependencies
  - âœ… Sufficient for structured aviation data
  - âš ï¸ Requires manual rule updates for new patterns

- **Runway Direction Disambiguation** (è·‘é“æ–¹å‘æ ‡è¯†è½¬æ¢):
  - é—®é¢˜: "è·‘é“ä¸¤æ‹å·¦å‘ç”Ÿé¸Ÿå‡»" ä¼šè¢«è¯¯è§£æä¸º position="è·‘é“27" + affected_part="å·¦å‘"
  - è§£å†³: åœ¨ Stage 1 é¢„å¤„ç†æ—¶å°† "è·‘é“XXå·¦/å³/ä¸­" è½¬æ¢ä¸º ICAO æ ¼å¼ "è·‘é“XXL/R/C"
  - æ•ˆæœ: "è·‘é“27Lå‘ç”Ÿé¸Ÿå‡»" ä¸­çš„ "L" ä¸å†ä¸ "å·¦å‘" æ­£åˆ™å†²çª

- **Future Enhancement**: True vector-based RAG
  - Requires: embedding model (e.g., sentence-transformers) + vector DB (Chroma/FAISS)
  - Pros: Better semantic understanding, automatic pattern learning
  - Cons: Additional dependencies, higher latency
  - Decision: Defer until rule coverage proves insufficient

**Examples**:

| Input | Output | Entities |
|-------|--------|----------|
| å·èˆªä¸‰å¹ºæ‹æ‹ è·‘é“æ´ä¸¤å·¦ æŠ¥å‘Šé¸Ÿå‡» | å·èˆª3U3177 è·‘é“02L æŠ¥å‘Šé¸Ÿå‡» | {flight_no: "3U3177", position: "02L", event_type: "bird_strike"} |
| è·‘é“ä¸¤æ‹å·¦å‘ç”Ÿç¡®è®¤é¸Ÿå‡» | è·‘é“27Lå‘ç”Ÿç¡®è®¤é¸Ÿå‡» | {position: "è·‘é“27L", event_type: "ç¡®è®¤é¸Ÿå‡»"} |
| è·‘é“27Lå‘ç”Ÿé¸Ÿå‡» å·¦å‘å—æŸ | è·‘é“27Lå‘ç”Ÿé¸Ÿå‡» å·¦å‘å—æŸ | {position: "è·‘é“27L", affected_part: "å·¦å‘"} |
| äº”æ´å¹ºæœºä½å‘ç°ç‡ƒæ²¹æ³„æ¼ | 501æœºä½å‘ç°ç‡ƒæ²¹æ³„æ¼ | {position: "501", fluid_type: "FUEL"} |
| æ»‘è¡Œé“Aä¸‰æœ‰æ¶²å‹æ²¹ | æ»‘è¡Œé“A3æœ‰æ¶²å‹æ²¹ | {position: "A3", fluid_type: "HYDRAULIC"} |

### LLM Configuration

`config/llm_config.py`:
- `LLMClientFactory` supports zhipu (GLM-4) and OpenAI-compatible APIs
- Uses LangChain's `ChatOpenAI` or `ChatZhipuAI`

## Supported Scenarios

- `oil_spill` (implemented): Fuel/hydraulic/oil leak handling with dedicated prompt.yaml
- `bird_strike` (example): Bird strike scenario with prompt.yaml (template for new scenarios)
- `tire_burst`, `runway_incursion` (planned)

**Adding New Scenarios**:
1. Create `scenarios/<name>/` directory with `prompt.yaml`
2. Register scenario class in `scenarios/base.py`
3. Optionally add `config.yaml`, `checklist.yaml`, `fsm_states.yaml`

See `scenarios/SCENARIO_GUIDE.md` for detailed instructions.

## API Endpoints

- `POST /event/start`: Start new incident session
- `POST /event/chat`: Continue conversation in session
- `GET /event/{session_id}`: Get session status
- `GET /event/{session_id}/report`: Get generated report
- `DELETE /event/{session_id}`: Close session

See [API Documentation](./docs/API_DOCUMENTATION.md) for detailed schemas and examples.

## Tool Development Guide

### Creating a New Tool

**Step 1: Create tool file**

```python
# tools/category/my_tool.py

from typing import Dict, Any
from tools.base import BaseTool

class MyTool(BaseTool):
    """
    Brief description of what this tool does.

    This tool should be used when...
    """

    # Tool metadata
    name = "my_tool"
    description = "Clear description visible to LLM for tool selection"

    def execute(self, state: Dict[str, Any], inputs: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute the tool logic.

        Args:
            state: Current AgentState dict
            inputs: Action inputs from LLM (action_input field)

        Returns:
            Dict with keys:
                - observation: String message shown to Agent
                - success: Boolean indicating success/failure
                - (optional) Additional state updates
        """
        # Extract inputs
        param1 = inputs.get("param1")
        param2 = inputs.get("param2", "default_value")

        # Validate inputs
        if not param1:
            return {
                "observation": "Error: param1 is required",
                "success": False
            }

        # Execute tool logic
        try:
            result = self._do_work(param1, param2)

            return {
                "observation": f"Successfully completed: {result}",
                "success": True,
                # Optional: Update state
                "state_updates": {
                    "my_data": result
                }
            }
        except Exception as e:
            return {
                "observation": f"Tool execution failed: {str(e)}",
                "success": False
            }

    def _do_work(self, param1: str, param2: str) -> Any:
        """Private helper method for actual work."""
        # Implementation here
        return "result"
```

**Step 2: Register tool in registry**

```python
# tools/registry.py

from tools.category.my_tool import MyTool

def register_all_tools():
    """Register all tools with the ToolRegistry."""

    # ... existing registrations ...

    # Register your tool
    ToolRegistry.register(
        MyTool(),
        scenarios=["oil_spill", "common"]  # Which scenarios can use this tool
    )
```

**Step 3: Add tests**

```python
# tests/tools/test_my_tool.py

import pytest
from tools.category.my_tool import MyTool

class TestMyTool:
    def test_execute_success(self):
        tool = MyTool()
        state = {"incident": {...}}
        inputs = {"param1": "value1"}

        result = tool.execute(state, inputs)

        assert result["success"] is True
        assert "Successfully completed" in result["observation"]

    def test_execute_missing_param(self):
        tool = MyTool()
        state = {}
        inputs = {}  # Missing param1

        result = tool.execute(state, inputs)

        assert result["success"] is False
        assert "param1 is required" in result["observation"]
```

### Tool Categories

Tools are organized by category:

- **information/**: Query tools that gather data
  - `ask_for_detail`: Ask user for specific field
  - `get_aircraft_info`: Retrieve flight information
  - `radiotelephony_normalizer`: Convert ATC phonetic alphabet to standard format (e.g., "æ´"â†’"0", "å¹º"â†’"1", "æ‹"â†’"7")
  - `smart_ask`: Intelligently ask multiple questions

- **spatial/**: Topology and geography analysis
  - `get_stand_location`: Find stand coordinates
  - `calculate_impact_zone`: BFS diffusion algorithm

- **knowledge/**: Knowledge base retrieval
  - `search_regulations`: RAG-style regulation lookup

- **assessment/**: Risk and impact evaluation
  - `assess_risk`: Rule-based risk scoring

- **action/**: External actions
  - `notify_department`: Send notifications
  - `generate_report`: Create final report

### Tool Best Practices

1. **Clear naming**: Tool name should be action-oriented (`get_`, `calculate_`, `assess_`)

2. **Descriptive description**: LLM uses this to decide when to use the tool

3. **Input validation**: Always validate inputs before execution

4. **Error handling**: Return structured error messages in `observation`

5. **State updates**: Return `state_updates` dict to modify AgentState

6. **Deterministic when possible**: Avoid LLM calls in tools for calculable logic

7. **Idempotent**: Tools should be safe to call multiple times

### Example: Creating "Get Weather" Tool

```python
# tools/information/get_weather.py

from typing import Dict, Any
import requests
from tools.base import BaseTool

class GetWeatherTool(BaseTool):
    """
    Retrieves current weather conditions for a location.
    Use this tool when you need weather information to assess
    environmental impact on incident handling.
    """

    name = "get_weather"
    description = "Get current weather conditions (temperature, wind, precipitation) for a specific location"

    def execute(self, state: Dict[str, Any], inputs: Dict[str, Any]) -> Dict[str, Any]:
        location = inputs.get("location")

        if not location:
            return {
                "observation": "Error: Location parameter is required",
                "success": False
            }

        try:
            # Call weather API (example)
            weather_data = self._fetch_weather(location)

            observation = (
                f"Weather at {location}:\n"
                f"- Temperature: {weather_data['temp']}Â°C\n"
                f"- Wind: {weather_data['wind_speed']} m/s, {weather_data['wind_direction']}\n"
                f"- Conditions: {weather_data['conditions']}"
            )

            return {
                "observation": observation,
                "success": True,
                "state_updates": {
                    "weather": weather_data
                }
            }
        except Exception as e:
            return {
                "observation": f"Failed to fetch weather: {str(e)}",
                "success": False
            }

    def _fetch_weather(self, location: str) -> Dict[str, Any]:
        # Actual API call implementation
        return {
            "temp": 25,
            "wind_speed": 5,
            "wind_direction": "NE",
            "conditions": "Clear"
        }

# Register in tools/registry.py:
# ToolRegistry.register(GetWeatherTool(), scenarios=["oil_spill", "common"])
```

## Code Quality Guidelines

### Error Handling Patterns

**Good: Specific exception handling**
```python
try:
    result = tool.execute(state, inputs)
except ToolExecutionError as e:
    logger.error(f"Tool execution failed: {e}", exc_info=True)
    return {"observation": f"Error: {e}", "success": False}
except ValidationError as e:
    logger.warning(f"Invalid input: {e}")
    return {"observation": f"Invalid input: {e}", "success": False}
```

**Bad: Catching all exceptions silently**
```python
try:
    result = tool.execute(state, inputs)
except:  # Too broad, hides bugs
    pass  # Silent failure - never do this!
```

### Logging Best Practices

Add logging to critical paths:

```python
import logging
logger = logging.getLogger(__name__)

def input_parser_node(state: AgentState) -> AgentState:
    logger.info(f"Starting input parsing for session {state['session_id']}")

    entities = extract_entities_hybrid(message)
    logger.debug(f"Extracted entities: {entities}")

    if not entities.get("position"):
        logger.warning("Position not extracted from user input")

    return updated_state
```

**Log levels:**
- `DEBUG`: Detailed diagnostic information
- `INFO`: General informational messages (state transitions, tool executions)
- `WARNING`: Unexpected situations that don't block execution
- `ERROR`: Error events that may still allow continued operation
- `CRITICAL`: Severe errors causing system failure

### Type Annotation Requirements

All functions must have type hints:

```python
# Good
def calculate_risk(
    fluid_type: str,
    engine_status: str,
    continuous: bool
) -> RiskAssessment:
    ...

# Bad
def calculate_risk(fluid_type, engine_status, continuous):
    ...
```

Use TypedDict for complex dictionaries:

```python
from typing import TypedDict

class ToolResult(TypedDict):
    observation: str
    success: bool
    state_updates: Dict[str, Any]
```

### Testing Requirements

Every tool must have:
1. Success case test
2. Failure case test
3. Edge case tests

```python
@pytest.mark.parametrize("fluid_type,expected_level", [
    ("FUEL", "HIGH"),
    ("HYDRAULIC", "MEDIUM"),
    ("OIL", "LOW"),
])
def test_assess_risk_levels(fluid_type, expected_level):
    ...
```

## Production Readiness Checklist

### Must-Have (Blocking Production)

- [ ] **Persistent storage** (PostgreSQL/Redis) for sessions
- [ ] **Docker containerization** with docker-compose
- [ ] **Structured logging** (JSON format) in all critical paths
- [ ] **Health check endpoint** (`/health` with liveness + readiness)
- [ ] **Basic metrics** (request count, response time, active sessions)
- [ ] **Database for reports** (replace file-based storage)
- [ ] **API authentication** (API key or JWT)
- [ ] **Secrets management** (remove hardcoded API keys)

### Should-Have (High Priority)

- [ ] **Configuration profiles** (dev/staging/prod separation)
- [ ] **Comprehensive error handling** (custom exception hierarchy)
- [ ] **Input validation middleware** (centralized validation)
- [ ] **Rate limiting** (per-IP request throttling)
- [ ] **CI/CD pipeline** (GitHub Actions for test + deploy)
- [ ] **Test coverage reporting** (pytest-cov with 80%+ target)
- [ ] **API documentation** (OpenAPI/Swagger specs)

### Nice-to-Have (Enhancement)

- [ ] **Caching layer** (Redis for frequent queries)
- [ ] **Message queue** (Celery/RabbitMQ for async processing)
- [ ] **Distributed tracing** (Jaeger/Datadog integration)
- [ ] **Custom Prometheus metrics** (business-specific metrics)
- [ ] **Multi-language support** (i18n for prompts and reports)
- [ ] **Automated rollback** (blue-green deployment)

Current Status: **45% production-ready** (Early Beta)

See [Production Readiness Assessment](./docs/PRODUCTION_READINESS.md) for detailed analysis.

## Troubleshooting Guide

### Common Issues

**Issue: "Tool not found: xyz"**
- **Cause**: Tool not registered in ToolRegistry or typo in tool name
- **Solution**: Check `tools/registry.py` registration, ensure tool name matches

**Issue: Session data lost after restart**
- **Cause**: Using MemorySessionStore (in-memory only)
- **Solution**: Implement PostgreSQL session store (see DEPLOYMENT_GUIDE.md)

**Issue: LLM output parsing fails**
- **Cause**: LLM returned non-JSON or malformed JSON
- **Solution**: Check `reasoning.py` fallback extraction logic, review system prompt

**Issue: FSM validation errors block progress**
- **Cause**: Mandatory actions not completed or preconditions not met
- **Solution**: Check `validation_result.errors` in Agent context, complete required actions

**Issue: Spatial analysis returns empty impact zone**
- **Cause**: Position not found in topology graph or invalid position format
- **Solution**: Verify position exists in `scripts/data_processing/topology_clustering_based.json`

### Debugging Tips

**Enable verbose logging:**
```bash
# In .env
LOG_LEVEL=DEBUG
```

**Enable LangSmith tracing:**
```bash
# In .env
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=aero-agent-dev
```

**Check session state:**
```python
# In terminal/debugging
from apps.api.session_store import get_session_store

store = get_session_store()
state = store.get("session_id_here")
print(state)
```

**Test individual tools:**
```bash
pytest tests/tools/test_assess_risk.py -v -s
```

**Validate topology data:**
```python
from tools/spatial/topology_loader import load_topology

graph = load_topology()
print(f"Nodes: {graph.number_of_nodes()}")
print(f"Edges: {graph.number_of_edges()}")
print(f"Sample node: {list(graph.nodes(data=True))[0]}")
```

### Performance Tuning

**Reduce auto-enrichment latency:**
- Increase ThreadPoolExecutor workers (default: 3)
- Cache flight data in Redis
- Pre-load topology graph on startup

**Optimize LLM calls:**
- Use shorter system prompts for simple scenarios
- Cache common LLM responses
- Use streaming for long outputs

**Database optimization:**
- Index session_id column
- Use connection pooling (SQLAlchemy)
- Implement read replicas for reporting queries

### Log Locations

- **Application logs**: stdout (capture with Docker logs)
- **LangSmith traces**: https://smith.langchain.com/
- **API request logs**: Check middleware logging in `apps/api/main.py`
- **Tool execution logs**: Currently minimal - add custom logging as needed

For more help, see:
- [Deployment Guide](./docs/DEPLOYMENT_GUIDE.md)
- [Architecture Decisions](./docs/ARCHITECTURE_DECISIONS.md)
- [GitHub Issues](https://github.com/yourrepo/issues)
