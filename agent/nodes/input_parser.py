"""
è¾“å…¥è§£æèŠ‚ç‚¹

èŒè´£ï¼š
1. è§£æç”¨æˆ·è¾“å…¥
2. è¯†åˆ«åœºæ™¯ç±»å‹
3. æå–å®ä½“ä¿¡æ¯ï¼ˆæ··åˆï¼šæ­£åˆ™ + LLMï¼‰
4. åˆå§‹åŒ– Checklist çŠ¶æ€
"""
import concurrent.futures
import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

from agent.state import AgentState, FSMState
from config.llm_config import get_llm_client
from config.settings import settings
from config.airline_codes import AIRLINE_CHINESE_TO_IATA
from scenarios.base import ScenarioRegistry
from agent.nodes.semantic_understanding import (
    understand_conversation,
    split_by_confidence,
    DEFAULT_CONFIDENCE_THRESHOLDS,
)


# é€šç”¨å®ä½“æå–æ­£åˆ™ï¼ˆåœºæ™¯é€šç”¨éƒ¨åˆ†ï¼‰
BASE_PATTERNS = {
    "position": [
        r"(\d{1,3})\s*(?:æ»‘è¡Œé“)",  # 12æ»‘è¡Œé“ -> 12
        r"(\d{2,3})\s*(?:æœºä½|åœæœºä½)",  # 501æœºä½, 32åœæœºä½ (æ•°å­—åœ¨å‰)
        r"(?:åœ¨|ä½äº)?(?:æœºä½|åœæœºä½)\s*å·?\s*(\d{2,3})",  # åœ¨32å·æœºä½, 501åœæœºä½, æœºä½32
        r"(æ»‘è¡Œé“|TWY)[_\s]?([A-Z]?\d+)",  # æ»‘è¡Œé“W2, TWY A3 (ä¿ç•™å®Œæ•´ä½ç½®)
        r"(è·‘é“|RWY)[_\s]?(\d{1,2}[LRC]?)",  # è·‘é“01L, è·‘é“2, RWY 09R (ä¿ç•™å®Œæ•´ä½ç½®)
        r"(\d{2,3})\s*å·",  # 234å·ï¼ˆå•ç‹¬å‡ºç°ï¼‰
    ],
    "fluid_type": [
        (r"æ¶²å‹æ²¹|æ¶²å‹æ¶²|hydraulic", "HYDRAULIC"),  # å…ˆåŒ¹é…æ¶²å‹æ²¹
        (r"æ»‘æ²¹|æ¶¦æ»‘æ²¹|æœºæ²¹|oil", "OIL"),  # å†åŒ¹é…æ»‘æ²¹
        (r"ç‡ƒæ²¹|èˆªæ²¹|æ²¹æ–™|jet|fuel|æ¼æ²¹|æ³„æ¼", "FUEL"),  # æœ€ååŒ¹é…ç‡ƒæ²¹
    ],
    "engine_status": [
        # ä¼˜å…ˆåŒ¹é…"æœªå…³é—­"ã€"æ²¡å…³"ç­‰åŒé‡å¦å®šï¼ˆè¡¨ç¤ºè¿è½¬ä¸­ï¼‰
        (r"å‘åŠ¨æœº.{0,5}(?:æœª|æ²¡æœ‰?).{0,3}(?:å…³é—­?|åœ)", "RUNNING"),
        # åŒ¹é…è¿è½¬çŠ¶æ€ï¼ˆåŒ…æ‹¬"è¿è½¬"ã€"åœ¨è¿è½¬"ã€"è¿˜åœ¨è¿è½¬"ç­‰ï¼‰
        (r"å‘åŠ¨æœº.{0,5}(?:åœ¨|è¿˜åœ¨|æ­£åœ¨)?\s*è¿è½¬", "RUNNING"),
        # åŒ¹é…è½¬çš„çŠ¶æ€ï¼ˆåŒ…æ‹¬"è½¬"ã€"åœ¨è½¬"ã€"è¿˜åœ¨è½¬"ç­‰ï¼‰
        (r"å‘åŠ¨æœº.{0,5}(?:åœ¨|è¿˜åœ¨|æ­£åœ¨)?.{0,3}è½¬(?![å·¥ä½œ])", "RUNNING"),
        # åŒ¹é…å…¶ä»–æ˜ç¡®çš„è¿è½¬çŠ¶æ€ï¼ˆè¿è¡Œã€å·¥ä½œã€å¯åŠ¨ï¼‰
        (r"å‘åŠ¨æœº.{0,5}(?:åœ¨|è¿˜åœ¨|æ­£åœ¨)?.{0,3}(?:è¿è¡Œ|å·¥ä½œ|å¯åŠ¨)", "RUNNING"),
        # åŒ¹é…å…³é—­çŠ¶æ€ï¼ˆå¸¦"å‘åŠ¨æœº"å‰ç¼€ï¼‰
        (r"å‘åŠ¨æœº.{0,5}(?:å·²å…³|å·²åœ|åœäº†|å…³äº†|å…³é—­|ç†„ç«)", "STOPPED"),
        # åŒ¹é…å…³é—­çŠ¶æ€ï¼ˆä¸å¸¦"å‘åŠ¨æœº"å‰ç¼€ï¼Œä½†åœ¨ä¸Šä¸‹æ–‡ä¸­æåˆ°å‘åŠ¨æœºç›¸å…³è¯ï¼‰
        (r"(?:å·²å…³|å·²åœ|åœäº†|å…³äº†|å…³é—­|ç†„ç«|åœè½¦)", "STOPPED"),
        # åŒ¹é…è¿è½¬çŠ¶æ€ï¼ˆä¸å¸¦"å‘åŠ¨æœº"å‰ç¼€ï¼‰
        (r"(?<!ä¸|æ²¡)(?:è¿è½¬|è¿è¡Œ|åœ¨è½¬|å¯åŠ¨ä¸­)(?!äº†|æ­¢)", "RUNNING"),
    ],
    "continuous": [
        (r"(?:è¿˜åœ¨|æŒç»­|ä¸æ–­|ä¸€ç›´).{0,3}(?:æ¼|æ»´|æµ)", True),
        (r"(?:å·²ç»|å·²|åœæ­¢).{0,3}(?:ä¸æ¼|åœäº†|æ­¢ä½)", False),
    ],
    "leak_size": [
        (r"å¤§é¢ç§¯|å¾ˆå¤§|å¤§é‡|>5ã¡|å¤§äº5", "LARGE"),
        (r"ä¸­ç­‰|ä¸€èˆ¬|1-5ã¡|1åˆ°5ã¡", "MEDIUM"),
        (r"å°é¢ç§¯|å¾ˆå°|å°‘é‡|ä¸€ç‚¹|<1ã¡|å°äº1", "SMALL"),
        (r"(?:é¢ç§¯)?(?:ä¸æ˜|ä¸æ¸…æ¥š|ä¸çŸ¥é“|å¾…ç¡®è®¤|æœªçŸ¥|æ— æ³•ç¡®å®š)", "UNKNOWN"),
    ],
    "aircraft": [
        r"èˆªç­(?:å·)?[ï¼š:\s]*([A-Z]{2}\d{3,4})",  # èˆªç­CES2355, èˆªç­å·: CA1234
        r"([A-Z]{2}\d{3,4})(?=\D|$)",  # CA1234 åé¢æ˜¯éæ•°å­—æˆ–ç»“å°¾
        # ä¸­æ–‡èˆªç©ºå…¬å¸ + èˆªç­å·
        r"(?:å›½èˆª|ä¸œèˆª|å—èˆª|æµ·èˆª|å·èˆª|å¦èˆª|æ·±èˆª|å±±èˆª|æ˜†èˆª|é¡ºä¸°|åœ†é€š|ä¸­è´§èˆª)\s*(\d{3,4})",  # å›½èˆª3242, ä¸œèˆª5678
        r"([B]-\d{4,5})",  # B-1234
    ],
}

_RADIOTELEPHONY_RULES = None


def _build_incident_and_checklist_templates(scenario_type: str) -> tuple[Dict[str, Any], Dict[str, bool]]:
    """æ ¹æ®åœºæ™¯é…ç½®æ„å»º incident/checklist æ¨¡æ¿ï¼Œä¾¿äºåˆ‡æ¢åœºæ™¯æ—¶é‡å»ºå­—æ®µã€‚"""
    scenario = ScenarioRegistry.get(scenario_type)
    if not scenario:
        incident_fields = {
            "fluid_type": None,
            "continuous": None,
            "engine_status": None,
            "position": None,
            "leak_size": None,
            "flight_no": None,
            "reported_by": None,
            "report_time": datetime.now().isoformat(),
        }
        checklist_fields = {k: False for k in incident_fields.keys()}
        return incident_fields, checklist_fields

    incident_fields: Dict[str, Any] = {}
    checklist_fields: Dict[str, bool] = {}
    for field in scenario.p1_fields + scenario.p2_fields:
        key = field.get("key")
        if key:
            incident_fields[key] = None
            checklist_fields[key] = False
    incident_fields["report_time"] = datetime.now().isoformat()

    return incident_fields, checklist_fields


def _load_radiotelephony_rules() -> Dict[str, Any]:
    global _RADIOTELEPHONY_RULES
    if _RADIOTELEPHONY_RULES is not None:
        return _RADIOTELEPHONY_RULES

    rules_path = (
        Path(__file__).resolve().parents[2] / "data" / "raw" / "Radiotelephony_ATC.json"
    )
    if not rules_path.exists():
        _RADIOTELEPHONY_RULES = {}
        return _RADIOTELEPHONY_RULES

    try:
        with rules_path.open("r", encoding="utf-8") as f:
            _RADIOTELEPHONY_RULES = json.load(f)
    except json.JSONDecodeError:
        _RADIOTELEPHONY_RULES = {}

    return _RADIOTELEPHONY_RULES


def normalize_radiotelephony_text(text: str) -> str:
    rules = _load_radiotelephony_rules()
    if not rules:
        return text

    digits_map = rules.get("digits", {})
    letters_map = rules.get("letters", {})
    if not digits_map and not letters_map:
        return text

    normalized = text

    if letters_map:
        for letter, spoken in letters_map.items():
            if spoken:
                normalized = normalized.replace(spoken, letter)

    if digits_map:
        reverse_digits = {v: k for k, v in digits_map.items()}
        for spoken, digit in reverse_digits.items():
            if spoken:
                normalized = normalized.replace(spoken, digit)

        normalized = re.sub(r"(?<=[A-Z0-9])\s+(?=[A-Z0-9])", "", normalized)

    # è§„èŒƒâ€œæ•°å­—+æ»‘è¡Œé“/è·‘é“/æœºä½â€é¡ºåºä¸ºâ€œæ»‘è¡Œé“12â€å½¢å¼
    normalized = re.sub(
        r"\b(\d{1,3})\s*(æ»‘è¡Œé“|è·‘é“|æœºä½)",
        lambda m: f"{m.group(2)}{m.group(1)}",
        normalized,
    )

    return normalized


def _extract_entities_legacy(text: str) -> Dict[str, Any]:
    """ä»æ–‡æœ¬ä¸­æå–å®ä½“ï¼ˆæ—§ç‰ˆï¼Œå…¼å®¹ä¿ç•™ï¼‰"""
    entities = {}

    # æå–ä½ç½® - å¢å¼ºæ¨¡å¼
    for pattern in PATTERNS["position"]:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            # å¦‚æœæœ‰ä¸¤ä¸ªæ•è·ç»„ï¼ˆå¦‚æ»‘è¡Œé“ã€è·‘é“ï¼‰ï¼Œç»„åˆå®Œæ•´ä½ç½®
            if len(match.groups()) == 2:
                prefix, suffix = match.group(1), match.group(2)
                # ä¿®å¤ï¼šç»Ÿä¸€ä¸åŠ ç©ºæ ¼ï¼Œä¿æŒç´§å‡‘æ ¼å¼ï¼ˆå¦‚"è·‘é“2"ã€"æ»‘è¡Œé“19"ï¼‰
                entities["position"] = f"{prefix}{suffix}"
            else:
                entities["position"] = match.group(1)
            break

    # å¦‚æœæ²¡æå–åˆ°ä½ç½®ï¼Œå°è¯•æ›´å¤šfallbackåŒ¹é…æ¨¡å¼
    if "position" not in entities:
        text_stripped = text.strip()

        # 1. çº¯æ•°å­—2-3ä½ï¼ˆå¦‚ "234", "501"ï¼‰- æœ€å¸¸è§çš„æœºä½å·æ ¼å¼
        if re.match(r'^\d{2,3}$', text_stripped):
            entities["position"] = text_stripped

        # 2. ç”¨æˆ·åªå›ç­”äº†ä½ç½®ç±»å‹å’Œæ•°å­—ï¼ˆå¦‚"è·‘é“2"ã€"æ»‘è¡Œé“19"ï¼‰
        elif re.match(r'^(è·‘é“|æ»‘è¡Œé“|æœºä½)\s*\d+', text_stripped, re.IGNORECASE):
            # æå–å®Œæ•´ä½ç½®å­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºæ ¼
            match = re.match(r'^(è·‘é“|æ»‘è¡Œé“|æœºä½)\s*(\d+)', text_stripped, re.IGNORECASE)
            if match:
                entities["position"] = f"{match.group(1)}{match.group(2)}"

        # 3. ç”¨æˆ·åœ¨ä¸€å¥è¯ä¸­æåˆ°äº†ä½ç½®ï¼ˆå¦‚"æˆ‘åœ¨è·‘é“2ï¼Œå‘åŠ¨æœºå…³é—­"ï¼‰
        else:
            # å°è¯•å†æ¬¡åŒ¹é…è·‘é“/æ»‘è¡Œé“+æ•°å­—ï¼ˆä¸è¦æ±‚å‰åæœ‰ç‰¹å®šè¯æ±‡ï¼‰
            match = re.search(r'(è·‘é“|æ»‘è¡Œé“|æœºä½|TWY|RWY)[_\s]?([A-Z]?\d+)', text, re.IGNORECASE)
            if match:
                entities["position"] = f"{match.group(1)}{match.group(2)}"
            else:
                # æœ€åå°è¯•ï¼šçº¯æ•°å­—ï¼ˆå¯èƒ½åŸ‹åœ¨å…¶ä»–æ–‡æœ¬ä¸­ï¼‰
                match = re.search(r'\b(\d{2,3})\b', text)
                if match:
                    # åªåœ¨æ²¡æœ‰å…¶ä»–ä½ç½®ä¿¡æ¯æ—¶æ‰ä½¿ç”¨çº¯æ•°å­—
                    entities["position"] = match.group(1)

    # æå–æ²¹æ¶²ç±»å‹
    for pattern, value in PATTERNS["fluid_type"]:
        if re.search(pattern, text):
            entities["fluid_type"] = value
            break

    # é¸Ÿå‡»åœºæ™¯ç‰¹æœ‰å­—æ®µ
    for pattern, value in PATTERNS.get("event_type", []):
        if re.search(pattern, text):
            entities["event_type"] = value
            break

    for pattern, value in PATTERNS.get("affected_part", []):
        if re.search(pattern, text):
            entities["affected_part"] = value
            break

    for pattern, value in PATTERNS.get("current_status", []):
        if re.search(pattern, text):
            entities["current_status"] = value
            break

    # æå–å‘åŠ¨æœºçŠ¶æ€
    for pattern, value in PATTERNS["engine_status"]:
        if re.search(pattern, text):
            entities["engine_status"] = value
            break

    # æå–æ˜¯å¦æŒç»­
    for pattern, value in PATTERNS["continuous"]:
        if re.search(pattern, text):
            entities["continuous"] = value
            break

    # æå–é¢ç§¯å¤§å°
    for pattern, value in PATTERNS["leak_size"]:
        if re.search(pattern, text):
            entities["leak_size"] = value
            break

    # æå–èˆªç­å·ï¼ˆä¸å†æå–æœºå·ï¼‰
    for pattern in PATTERNS["aircraft"]:
        match = re.search(pattern, text)
        if match:
            value = match.group(1)
            # è·³è¿‡æœºå·æ ¼å¼ï¼ˆB-å¼€å¤´ï¼‰ï¼Œåªæå–èˆªç­å·
            if value.startswith("B-"):
                continue
            elif value.isdigit():
                # å¯èƒ½æ˜¯ä¸­æ–‡èˆªç©ºå…¬å¸åç§°ï¼Œéœ€è¦æŸ¥æ‰¾æ˜¯å“ªä¸ª
                for cn_name, code in AIRLINE_CHINESE_TO_IATA.items():
                    if cn_name in text:
                        # ä¿å­˜åŸå§‹æ˜¾ç¤ºæ ¼å¼ï¼ˆä¸­æ–‡+æ•°å­—ï¼‰
                        entities["flight_no_display"] = f"{cn_name}{value}"
                        # ä¿å­˜IATAæ ¼å¼ç”¨äºè½¬æ¢
                        entities["flight_no"] = f"{code}{value}"
                        break
            else:
                # IATAæˆ–ICAOæ ¼å¼
                # ä¿å­˜åŸå§‹æ ¼å¼ç”¨äºæ˜¾ç¤º
                entities["flight_no_display"] = value
                entities["flight_no"] = value
            break

    return entities


def identify_scenario(text: str) -> str:
    """
    è¯†åˆ«åœºæ™¯ç±»å‹ï¼ˆåŸºäºåœºæ™¯æ³¨å†Œçš„å…³é”®è¯ï¼Œæ”¯æŒä¼˜å…ˆçº§ï¼‰
    """
    text_lower = text.lower()
    candidates: list[tuple[int, str]] = []

    for name in ScenarioRegistry.list_all():
        scenario = ScenarioRegistry.get(name)
        if not scenario:
            continue
        keywords = getattr(scenario, "keywords", []) or []
        priority = scenario.metadata.get("priority", 100)
        if any(kw.lower() in text_lower for kw in keywords):
            candidates.append((priority, name))

    if candidates:
        candidates.sort(key=lambda x: x[0])
        return candidates[0][1]

    # å›é€€ï¼šä¿æŒä¸å†å²é€»è¾‘ä¸€è‡´
    oil_keywords = ["æ¼æ²¹", "æ³„æ¼", "ç‡ƒæ²¹", "æ¶²å‹æ²¹", "æ»‘æ²¹", "æ²¹æ¶²", "æ¼æ¶²"]
    bird_keywords = ["é¸Ÿå‡»", "æ’é¸Ÿ", "é¸Ÿæ’", "ç–‘ä¼¼é¸Ÿå‡»"]
    if any(kw in text_lower for kw in bird_keywords):
        return "bird_strike"
    if any(kw in text_lower for kw in oil_keywords):
        return "oil_spill"

    return "oil_spill"


def update_checklist(incident: Dict[str, Any], base_checklist: Dict[str, bool] = None) -> Dict[str, bool]:
    """æ ¹æ®äº‹ä»¶ä¿¡æ¯æ›´æ–° Checklist çŠ¶æ€ï¼ˆä¿æŒåœºæ™¯å­—æ®µï¼‰"""
    if base_checklist:
        return {k: incident.get(k) is not None for k in base_checklist.keys()}

    return {
        "flight_no": incident.get("flight_no") is not None,
        "fluid_type": incident.get("fluid_type") is not None,
        "continuous": incident.get("continuous") is not None,
        "engine_status": incident.get("engine_status") is not None,
        "position": incident.get("position") is not None,
        "leak_size": incident.get("leak_size") is not None,
    }


def _execute_future_with_timeout(
    future: concurrent.futures.Future,
    timeout: int = 10,
) -> Dict[str, Any] | None:
    """æ‰§è¡Œ future å¹¶å¤„ç†è¶…æ—¶å’Œå¼‚å¸¸"""
    try:
        return future.result(timeout=timeout)
    except concurrent.futures.TimeoutError:
        logger.debug("Future execution timed out")
        return None
    except Exception as e:
        logger.debug("Future execution failed: %s", e)
        return None


def _fetch_aircraft_info(incident: Dict[str, Any], flight_no: str) -> Dict[str, Any]:
    """è·å–èˆªç­ä¿¡æ¯"""
    from tools.information.get_aircraft_info import GetAircraftInfoTool
    tool = GetAircraftInfoTool()
    return tool.execute(incident, {"flight_no": flight_no})


def _fetch_flight_plan(incident: Dict[str, Any], flight_no: str) -> Dict[str, Any]:
    """è·å–èˆªç­è®¡åˆ’"""
    from tools.information.flight_plan_lookup import FlightPlanLookupTool
    tool = FlightPlanLookupTool()
    return tool.execute(incident, {"flight_no": flight_no})


def _fetch_stand_location(incident: Dict[str, Any]) -> Dict[str, Any]:
    """è·å–ä½ç½®æ‹“æ‰‘ä¿¡æ¯"""
    from tools.spatial.get_stand_location import GetStandLocationTool
    tool = GetStandLocationTool()
    return tool.execute(incident, {})


def _fetch_weather_info(state: Dict[str, Any]) -> Dict[str, Any]:
    """è·å–æ°”è±¡ä¿¡æ¯ï¼ˆè‡ªåŠ¨æŸ¥è¯¢æœ€æ–°æ•°æ®ï¼‰"""
    from tools.information.get_weather import GetWeatherTool
    try:
        tool = GetWeatherTool()
        # ä¸æŒ‡å®šæ—¶é—´ï¼Œè‡ªåŠ¨è¿”å›æœ€æ–°æ•°æ®
        # ä½¿ç”¨ state è€Œä¸æ˜¯ incidentï¼Œä»¥ä¾¿å·¥å…·èƒ½è®¿é—® position ä¿¡æ¯
        result = tool.execute(state, {"location": "æ¨è"})
        logger.info(f"æ°”è±¡æŸ¥è¯¢å®Œæˆ: location={result.get('weather', {}).get('location') if result.get('weather') else 'failed'}")
        return result
    except Exception as e:
        logger.error(f"æ°”è±¡æŸ¥è¯¢å¼‚å¸¸: {e}")
        return {"observation": f"æ°”è±¡æŸ¥è¯¢å¼‚å¸¸: {str(e)}"}


def _calculate_impact_zone(
    incident: Dict[str, Any],
    position: str,
    risk_level: str,
) -> Dict[str, Any]:
    """è®¡ç®—å½±å“èŒƒå›´"""
    from tools.spatial.calculate_impact_zone import CalculateImpactZoneTool
    tool = CalculateImpactZoneTool()
    impact_inputs = {
        "position": position,
        "fluid_type": incident.get("fluid_type"),
        "risk_level": risk_level,
    }
    return tool.execute(incident, impact_inputs)


def _analyze_position_impact(
    incident: Dict[str, Any],
    risk_assessment: Dict[str, Any],
) -> Dict[str, Any]:
    """åˆ†æä½ç½®å½±å“"""
    from tools.spatial.analyze_position_impact import AnalyzePositionImpactTool
    tool = AnalyzePositionImpactTool()
    temp_state = {
        "incident": incident,
        "risk_assessment": risk_assessment,
    }
    return tool.execute(temp_state, {})


def apply_auto_enrichment(
    state: AgentState,
    current_incident: Dict[str, Any],
) -> Dict[str, Any]:
    """æ ¹æ®å·²çŸ¥ä¿¡æ¯è‡ªåŠ¨è¡¥å……èˆªç­ã€ä½ç½®ä¸å½±å“åˆ†æï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰"""
    incident = dict(current_incident)
    updates: Dict[str, Any] = {}
    observations: list[str] = []

    position = incident.get("position")
    flight_no = incident.get("flight_no") or incident.get("flight_no_display", "")
    spatial_analysis = dict(state.get("spatial_analysis", {}) or {})

    # ========== ç¬¬ä¸€é˜¶æ®µï¼šå¹¶è¡Œæ‰§è¡Œç‹¬ç«‹çš„ä¿¡æ¯æŸ¥è¯¢ ==========
    phase1_futures: Dict[str, concurrent.futures.Future] = {}

    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        if flight_no and not incident.get("airline"):
            phase1_futures["aircraft_info"] = executor.submit(
                _fetch_aircraft_info, incident, flight_no
            )

        if flight_no and not state.get("flight_plan_table"):
            phase1_futures["flight_plan"] = executor.submit(
                _fetch_flight_plan, incident, flight_no
            )

        if position and not spatial_analysis:
            phase1_futures["stand_location"] = executor.submit(
                _fetch_stand_location, incident
            )

        # è‡ªåŠ¨æŸ¥è¯¢æ°”è±¡ä¿¡æ¯ï¼ˆåªè¦æœ‰ä½ç½®ä¿¡æ¯ï¼‰
        if position and not state.get("weather"):
            # æ„å»ºä¸´æ—¶stateï¼ŒåŒ…å«å½“å‰çš„incidentä¿¡æ¯
            temp_state = {"incident": incident}
            phase1_futures["weather_info"] = executor.submit(
                _fetch_weather_info, temp_state
            )

        # æ”¶é›†ç¬¬ä¸€é˜¶æ®µç»“æœ
        for key, future in phase1_futures.items():
            # æ°”è±¡æŸ¥è¯¢ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆ30ç§’ï¼‰ï¼Œå› ä¸ºé¦–æ¬¡åŠ è½½æ•°æ®å¯èƒ½è¾ƒæ…¢
            timeout = 30 if key == "weather_info" else 10
            result = _execute_future_with_timeout(future, timeout=timeout)
            if not result:
                continue

            if key == "aircraft_info" and result.get("incident"):
                for k, v in result["incident"].items():
                    if v and k not in incident:
                        incident[k] = v
                if result.get("observation"):
                    observations.append(f"\nèˆªç­ä¿¡æ¯: {result['observation']}")

            elif key == "flight_plan":
                if result.get("observation"):
                    observations.append(f"\nèˆªç­è®¡åˆ’: {result['observation']}")
                    updates["flight_plan_observation"] = result["observation"]
                if result.get("flight_plan_table"):
                    updates["flight_plan_table"] = result["flight_plan_table"]

            elif key == "stand_location":
                if result.get("observation"):
                    observations.append(f"\nä½ç½®ä¿¡æ¯: {result['observation']}")
                if result.get("spatial_analysis"):
                    spatial_analysis.update(result["spatial_analysis"])

            elif key == "weather_info":
                if result:
                    if result.get("observation"):
                        observations.append(f"\nğŸŒ¤ï¸ æ°”è±¡ä¿¡æ¯: {result['observation']}")
                    if result.get("weather"):
                        updates["weather"] = result["weather"]
                        logger.info(f"æ°”è±¡æŸ¥è¯¢æˆåŠŸ: {result['weather'].get('location')}")
                else:
                    # æ°”è±¡æŸ¥è¯¢å¤±è´¥æˆ–è¶…æ—¶ï¼Œè®°å½•è­¦å‘Šä½†ä¸é˜»å¡æµç¨‹
                    logger.warning(f"æ°”è±¡æŸ¥è¯¢è¶…æ—¶æˆ–å¤±è´¥ (position={position})")

    # ========== ç¬¬äºŒé˜¶æ®µï¼šä¾èµ–ç¬¬ä¸€é˜¶æ®µç»“æœçš„è®¡ç®— ==========
    phase2_futures: Dict[str, concurrent.futures.Future] = {}
    risk_level = state.get("risk_assessment", {}).get("level", "R2")

    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        if position and not incident.get("impact_zone"):
            phase2_futures["impact_zone"] = executor.submit(
                _calculate_impact_zone, incident, position, risk_level
            )

        if position and incident.get("fluid_type") and not state.get("position_impact_analysis"):
            risk_assessment = state.get("risk_assessment", {"level": "R2"})
            phase2_futures["position_impact"] = executor.submit(
                _analyze_position_impact, incident, risk_assessment
            )

        # æ”¶é›†ç¬¬äºŒé˜¶æ®µç»“æœ
        position_impact_analysis: Dict[str, Any] = {}

        for key, future in phase2_futures.items():
            result = _execute_future_with_timeout(future)
            if not result:
                continue

            if key == "impact_zone":
                if result.get("observation"):
                    observations.append(f"\nå½±å“èŒƒå›´: {result['observation']}")
                if result.get("spatial_analysis"):
                    for k, v in result["spatial_analysis"].items():
                        if k not in spatial_analysis:
                            spatial_analysis[k] = v
                    incident["impact_zone"] = result["spatial_analysis"]

            elif key == "position_impact":
                if result.get("observation"):
                    observations.append(f"\n{result['observation']}")
                if result.get("position_impact_analysis"):
                    position_impact_analysis = result["position_impact_analysis"]

    # ========== æ±‡æ€»ç»“æœ ==========
    updates["incident"] = incident
    if spatial_analysis:
        updates["spatial_analysis"] = spatial_analysis
    if position_impact_analysis:
        updates["position_impact_analysis"] = position_impact_analysis
    if observations:
        updates["enrichment_observation"] = "".join(observations)

    return updates


def input_parser_node(state: AgentState) -> Dict[str, Any]:
    """
    è¾“å…¥è§£æèŠ‚ç‚¹

    èŒè´£ï¼š
    1. ä»ç”¨æˆ·æ¶ˆæ¯ä¸­æå–å®ä½“
    2. è¯†åˆ«åœºæ™¯ç±»å‹
    3. æ›´æ–° incident å’Œ checklist çŠ¶æ€
    4. è‡ªåŠ¨è·å–èˆªç­ä¿¡æ¯ï¼ˆå¦‚æœèˆªç­å·å·²çŸ¥ï¼‰
    """
    # è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
    messages = state.get("messages", [])
    if not messages:
        return {
            "error": "æ²¡æœ‰æ”¶åˆ°ç”¨æˆ·è¾“å…¥",
            "next_node": "end",
        }

    # è·å–ç”¨æˆ·è¾“å…¥
    user_message = ""
    for msg in reversed(messages):
        if msg.get("role") == "user":
            user_message = msg.get("content", "")
            break

    if not user_message:
        return {
            "error": "æ²¡æœ‰æ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯",
            "next_node": "end",
        }

    normalized_message = normalize_radiotelephony_text(user_message)

    # ========== æ–°å¢: èˆªç©ºè¯»æ³•æ·±åº¦è§„èŒƒåŒ– (LLM + RAG) ==========
    from tools.information.radiotelephony_normalizer import RadiotelephonyNormalizerTool

    normalizer = RadiotelephonyNormalizerTool()
    normalization_result = normalizer.execute(state, {"text": normalized_message})

    # ä½¿ç”¨å¢å¼ºåçš„æ–‡æœ¬ (Fallback: å¦‚æœå¤±è´¥ä½¿ç”¨åŸæ–‡æœ¬)
    enhanced_message = normalization_result.get("normalized_text", normalized_message)
    pre_extracted_entities = normalization_result.get("entities", {})
    normalization_confidence = normalization_result.get("confidence", 0.5)

    logger.info(f"èˆªç©ºè¯»æ³•è§„èŒƒåŒ–: {normalized_message} â†’ {enhanced_message} (ç½®ä¿¡åº¦: {normalization_confidence:.2f})")
    if pre_extracted_entities:
        logger.info(f"é¢„æå–å®ä½“: {pre_extracted_entities}")
    # ================================================================

    # è¯†åˆ«åœºæ™¯ç±»å‹ï¼ˆä¿ç•™å·²æœ‰åœºæ™¯ä¼˜å…ˆçº§ï¼Œé¿å…é™çº§ï¼‰
    detected_scenario = identify_scenario(enhanced_message)
    scenario_type = _select_scenario(state.get("scenario_type", ""), detected_scenario)

    # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
    history = build_history_context(messages)

    # åŸºäºåœºæ™¯æ¨¡æ¿é‡å»º incident/checklistï¼Œä¿ç•™å·²çŸ¥å­—æ®µ
    incident_template, checklist_template = _build_incident_and_checklist_templates(scenario_type)
    current_incident = incident_template
    for key, value in state.get("incident", {}).items():
        if key in current_incident and value not in [None, ""]:
            current_incident[key] = value
    semantic_understanding: Dict[str, Any] = {}
    semantic_validation: Dict[str, Any] = {}
    extracted: Dict[str, Any] = {}

    if settings.ENABLE_SEMANTIC_UNDERSTANDING:
        semantic_understanding = understand_conversation(
            current_message=normalized_message,
            conversation_history=messages,
            known_facts=current_incident,
            fsm_state=state.get("fsm_state", FSMState.INIT.value),
        )

        accepted, low_confidence_fields = split_by_confidence(
            semantic_understanding.get("extracted_facts", {}),
            semantic_understanding.get("confidence_scores", {}),
            DEFAULT_CONFIDENCE_THRESHOLDS,
        )

        # åŸºäºè§„åˆ™çš„å¿«é€Ÿæå–ï¼ˆæ›´ç¨³å®šï¼‰ï¼Œä½œä¸ºè¡¥å……
        deterministic_entities = extract_entities(normalized_message, scenario_type)
        extracted.update(deterministic_entities)
        extracted.update(accepted)

        # åˆå¹¶ä¿¡æ¯å¹¶è®°å½•æ½œåœ¨å†²çª
        semantic_issues = list(semantic_understanding.get("semantic_issues", []))
        for key, value in extracted.items():
            previous_value = current_incident.get(key)
            if previous_value not in [None, ""] and value is not None and previous_value != value:
                semantic_issues.append(f"{key} ä¸å·²çŸ¥ä¿¡æ¯ä¸ä¸€è‡´ï¼Œè¯·ç¡®è®¤")
            if value is not None:
                current_incident[key] = value

        # è¯­ä¹‰éªŒè¯ç»“æœï¼ˆç¼ºå¤±/ä½ç½®ä¿¡åº¦/çŸ›ç›¾ï¼‰
        scenario = ScenarioRegistry.get(scenario_type)
        required_fields = _infer_required_fields(scenario, current_incident)

        checklist = update_checklist(current_incident, checklist_template)
        missing_fields = [field for field in required_fields if not checklist.get(field, False)]

        semantic_validation = {
            "missing_fields": missing_fields,
            "low_confidence_fields": low_confidence_fields,
            "semantic_issues": semantic_issues,
            "summary": semantic_understanding.get("conversation_summary", ""),
        }
    else:
        # æå–å®ä½“ï¼ˆæ··åˆæ–¹æ¡ˆï¼šæ­£åˆ™ + LLMï¼Œæ›´çµæ´»ï¼‰
        extracted = extract_entities_hybrid(enhanced_message, history, scenario_type)

        # åˆå¹¶é¢„æå–çš„å®ä½“ (è§„èŒƒåŒ–å·¥å…·çš„ç»“æœä¼˜å…ˆçº§æœ€é«˜ï¼Œå› ä¸ºæ˜¯LLM+RAGå¤„ç†è¿‡çš„)
        # å…ˆä½¿ç”¨å¸¸è§„æå–çš„ç»“æœ
        for key, value in extracted.items():
            if value is not None:
                current_incident[key] = value

        # ç„¶åç”¨è§„èŒƒåŒ–å·¥å…·çš„ç»“æœè¦†ç›–ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        for key, value in pre_extracted_entities.items():
            if value:
                if key in current_incident and current_incident[key] != value:
                    logger.info(f"è§„èŒƒåŒ–å·¥å…·è¦†ç›– {key}: {current_incident[key]} â†’ {value}")
                current_incident[key] = value

    # è‡ªåŠ¨è¡¥å……ä¿¡æ¯ï¼ˆèˆªç­ã€ä½ç½®ã€å½±å“åˆ†æç­‰ï¼‰
    enrichment = apply_auto_enrichment(state, current_incident)
    current_incident = enrichment.get("incident", current_incident)
    spatial_analysis = enrichment.get("spatial_analysis", {})
    position_impact_analysis = enrichment.get("position_impact_analysis", {})
    flight_plan_table = enrichment.get("flight_plan_table")
    flight_plan_observation = enrichment.get("flight_plan_observation")
    weather_info = enrichment.get("weather")  # æå–æ°”è±¡ä¿¡æ¯
    enrichment_observation = enrichment.get("enrichment_observation", "")  # æå–å¢å¼ºè§‚å¯Ÿä¿¡æ¯

    # æ›´æ–° checklistï¼ˆä¿æŒåœºæ™¯å­—æ®µï¼‰
    checklist = update_checklist(current_incident, checklist_template)
    if semantic_validation:
        scenario = ScenarioRegistry.get(scenario_type)
        required_fields = _infer_required_fields(scenario, current_incident)
        semantic_validation["missing_fields"] = [
            field for field in required_fields if not checklist.get(field, False)
        ]

    # è®°å½•è§£æç»“æœ
    observation_parts = []

    # æ·»åŠ è§„èŒƒåŒ–ä¿¡æ¯
    if normalization_confidence > 0.7:
        observation_parts.append(f"èˆªç©ºè¯»æ³•è§„èŒƒåŒ–: {normalized_message} â†’ {enhanced_message}")

    observation_parts.append(f"æå–å®ä½“: {extracted}")

    if semantic_understanding:
        observation_parts.append(f"è¯­ä¹‰ç†è§£: {semantic_understanding.get('conversation_summary', '')}")
    if enrichment.get("enrichment_observation"):
        observation_parts.append(enrichment.get("enrichment_observation"))
    reasoning_step = {
        "step": 0,
        "thought": f"è§£æç”¨æˆ·è¾“å…¥ï¼Œè¯†åˆ«ä¸º{scenario_type}åœºæ™¯",
        "action": "input_parser",
        "action_input": {"text": normalized_message, "raw_text": user_message},
        "observation": "\n".join(observation_parts),
        "timestamp": datetime.now().isoformat(),
    }

    existing_steps = state.get("reasoning_steps", [])
    reasoning_steps = existing_steps + [reasoning_step] if existing_steps else [reasoning_step]
    iteration_count = state.get("iteration_count", 0) or 1

    return {
        "scenario_type": scenario_type,
        "incident": current_incident,
        "checklist": checklist,
        "awaiting_user": False,
        **({"spatial_analysis": spatial_analysis} if spatial_analysis else {}),
        **({"position_impact_analysis": position_impact_analysis} if position_impact_analysis else {}),
        **({"flight_plan_table": flight_plan_table} if flight_plan_table else {}),
        **({"flight_plan_observation": flight_plan_observation} if flight_plan_observation else {}),
        **({"weather": weather_info} if weather_info else {}),  # æ·»åŠ æ°”è±¡ä¿¡æ¯
        **({"enrichment_observation": enrichment_observation} if enrichment_observation else {}),  # æ·»åŠ å¢å¼ºè§‚å¯Ÿä¿¡æ¯
        **({"normalization_result": normalization_result} if normalization_confidence > 0.7 else {}),  # æ·»åŠ è§„èŒƒåŒ–ç»“æœ
        "reasoning_steps": reasoning_steps,
        "current_node": "input_parser",
        "next_node": "reasoning",
        "iteration_count": iteration_count,
        **({"semantic_understanding": semantic_understanding} if semantic_understanding else {}),
        **({"semantic_validation": semantic_validation} if semantic_validation else {}),
    }


def build_history_context(messages: list) -> str:
    """æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡"""
    if not messages:
        return "æ— å†å²å¯¹è¯"

    context_parts = []
    for msg in messages[-5:]:  # åªå–æœ€è¿‘5æ¡
        role = msg.get("role", "")
        content = msg.get("content", "")
        context_parts.append(f"{role}: {content}")

    return "\n".join(context_parts)


# ============================================================
# LLM å®ä½“æå–ï¼ˆæ›´çµæ´»çš„æ–¹æ¡ˆï¼‰
# ============================================================

LLM_EXTRACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæœºåœºåº”æ€¥å“åº”ç³»ç»Ÿçš„äº‹ä»¶ä¿¡æ¯æå–åŠ©æ‰‹ã€‚

æ ¹æ®å¯¹è¯å†å²å’Œå½“å‰ç”¨æˆ·è¾“å…¥ï¼Œæå–äº‹ä»¶ä¿¡æ¯ã€‚è¾“å‡º JSON æ ¼å¼ï¼š

## å¯¹è¯å†å²ï¼š
{history}

## å½“å‰ç”¨æˆ·è¾“å…¥ï¼š
{user_input}

## éœ€è¦æå–çš„å­—æ®µï¼š
- position: äº‹å‘ä½ç½®ï¼ˆå¦‚ 501ã€A3ã€01L ç­‰ï¼Œå¯åªå¡«æ•°å­—è¡¨ç¤ºæœºä½å·ï¼‰
- fluid_type: æ²¹æ¶²ç±»å‹ï¼ˆFUEL=ç‡ƒæ²¹, HYDRAULIC=æ¶²å‹æ²¹, OIL=æ»‘æ²¹ï¼‰
- engine_status: å‘åŠ¨æœºçŠ¶æ€ï¼ˆRUNNING=è¿è½¬ä¸­, STOPPED=å·²åœæ­¢ï¼‰
- continuous: æ˜¯å¦æŒç»­æ³„æ¼ï¼ˆtrue=æ˜¯, false=å¦ï¼‰
- leak_size: æ³„æ¼é¢ç§¯ï¼ˆLARGE=å¤§é¢ç§¯, MEDIUM=ä¸­ç­‰, SMALL=å°é¢ç§¯, UNKNOWN=ä¸æ˜/ä¸æ¸…æ¥šï¼‰
- flight_no: èˆªç­å·ï¼ˆå¦‚ CA1234ã€MU5678ï¼‰
- phase: é£è¡Œé˜¶æ®µï¼ˆPUSHBACK/TAXI/TAKEOFF_ROLL/INITIAL_CLIMB/CRUISE/DESCENT/APPROACH/LANDING_ROLL/ON_STAND/UNKNOWNï¼‰
- evidence: è¿¹è±¡å¼ºåº¦ï¼ˆCONFIRMED_STRIKE_WITH_REMAINS/SYSTEM_WARNING/ABNORMAL_NOISE_VIBRATION/SUSPECTED_ONLY/NO_ABNORMALITYï¼‰
- bird_info: é¸Ÿç±»ä¿¡æ¯ï¼ˆLARGE_BIRD/FLOCK/MEDIUM_SMALL_SINGLE/UNKNOWNï¼‰
- ops_impact: è¿è¡Œå½±å“ï¼ˆRTO_OR_RTB/BLOCKING_RUNWAY_OR_TAXIWAY/REQUEST_MAINT_CHECK/NO_OPS_IMPACT/UNKNOWNï¼‰
- crew_request: æœºç»„è¯·æ±‚ï¼ˆè‡ªç”±æ–‡æœ¬ï¼Œå¦‚è¿”èˆª/å¤‡é™/æ£€æŸ¥/æ”¯æ´ç­‰ï¼‰

## æ™ºèƒ½æå–è§„åˆ™ï¼š
1. å¦‚æœç”¨æˆ·åªè¾“å…¥çº¯æ•°å­—ï¼ˆ2-3ä½ï¼‰ï¼Œä¸”é—®é¢˜æ˜¯å…³äºä½ç½®çš„ â†’ è¯†åˆ«ä¸ºæœºä½å·
2. å¦‚æœç”¨æˆ·è¾“å…¥èˆªç­å·æ ¼å¼ï¼ˆ2å­—æ¯+3-4æ•°å­—ï¼‰ â†’ è¯†åˆ«ä¸º flight_no
3. å¦‚æœç”¨æˆ·å›ç­”"æ˜¯/å¦/ä¸çŸ¥é“"ç­‰ï¼Œä¸”æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ â†’ è¿”å›ç©º {}
4. **é‡è¦**ï¼šå¦‚æœç”¨æˆ·æ˜ç¡®è¡¨ç¤ºæŸä¸ªä¿¡æ¯"ä¸æ˜"ã€"ä¸æ¸…æ¥š"ã€"ä¸çŸ¥é“"ï¼Œæå–ä¸º UNKNOWNï¼ˆä¸è¦è¿”å›ç©ºï¼‰
5. åªæå–æ˜ç¡®çš„ä¿¡æ¯ï¼Œä¸è¦çŒœæµ‹

## è¾“å‡ºæ ¼å¼ï¼š
{{"position": "...", "fluid_type": "FUEL", "engine_status": "RUNNING", "phase": "TAXI", ...}}

å¦‚æœæ— æ³•æå–ä»»ä½•æœ‰æ•ˆä¿¡æ¯ï¼Œè¿”å› {{}}
"""

POS_TYPE_MAP = {
    "ç‡ƒæ²¹": "FUEL", "èˆªæ²¹": "FUEL", "èˆªç©ºç‡ƒæ²¹": "FUEL", "jet": "FUEL", "fuel": "FUEL",
    "æ¶²å‹æ²¹": "HYDRAULIC", "æ¶²å‹": "HYDRAULIC", "hydraulic": "HYDRAULIC",
    "æ»‘æ²¹": "OIL", "æœºæ²¹": "OIL", "æ¶¦æ»‘æ²¹": "OIL", "oil": "OIL",
}

ENG_TYPE_MAP = {
    "è¿è½¬": "RUNNING", "è¿è¡Œ": "RUNNING", "åœ¨è½¬": "RUNNING", "å¯åŠ¨": "RUNNING",
    "åœæ­¢": "STOPPED", "å…³é—­": "STOPPED", "å…³è½¦": "STOPPED", "ç†„ç«": "STOPPED",
}

SIZE_TYPE_MAP = {
    "å¤§é¢ç§¯": "LARGE", "å¾ˆå¤§": "LARGE", "å¤§é‡": "LARGE", ">5": "LARGE", "5ã¡": "LARGE",
    "ä¸­ç­‰": "MEDIUM", "ä¸€èˆ¬": "MEDIUM", "1-5": "MEDIUM",
    "å°é¢ç§¯": "SMALL", "å°‘é‡": "SMALL", "ä¸€ç‚¹": "SMALL", "<1": "SMALL",
    "ä¸æ˜": "UNKNOWN", "ä¸æ¸…æ¥š": "UNKNOWN", "ä¸çŸ¥é“": "UNKNOWN", "æœªçŸ¥": "UNKNOWN", "å¾…ç¡®è®¤": "UNKNOWN",
}

PHASE_TYPE_MAP = {
    "æ¨å‡º": "PUSHBACK",
    "æ»‘è¡Œ": "TAXI",
    "èµ·é£æ»‘è·‘": "TAKEOFF_ROLL",
    "èµ·é£": "TAKEOFF_ROLL",
    "çˆ¬å‡": "INITIAL_CLIMB",
    "èµ·é£å": "INITIAL_CLIMB",
    "å·¡èˆª": "CRUISE",
    "ä¸‹é™": "DESCENT",
    "è¿›è¿‘": "APPROACH",
    "è½åœ°æ»‘è·‘": "LANDING_ROLL",
    "ç€é™†æ»‘è·‘": "LANDING_ROLL",
    "åœæœºä½": "ON_STAND",
    "ä¸æ˜": "UNKNOWN",
    "æœªçŸ¥": "UNKNOWN",
}

EVIDENCE_TYPE_MAP = {
    "æ®‹ç•™": "CONFIRMED_STRIKE_WITH_REMAINS",
    "ç¾½æ¯›": "CONFIRMED_STRIKE_WITH_REMAINS",
    "è¡€è¿¹": "CONFIRMED_STRIKE_WITH_REMAINS",
    "ç¡®è®¤æ’å‡»": "CONFIRMED_STRIKE_WITH_REMAINS",
    "å‘Šè­¦": "SYSTEM_WARNING",
    "æŠ¥è­¦": "SYSTEM_WARNING",
    "ECAM": "SYSTEM_WARNING",
    "EICAS": "SYSTEM_WARNING",
    "å¼‚å“": "ABNORMAL_NOISE_VIBRATION",
    "æŒ¯åŠ¨": "ABNORMAL_NOISE_VIBRATION",
    "éœ‡åŠ¨": "ABNORMAL_NOISE_VIBRATION",
    "ä»…æ€€ç–‘": "SUSPECTED_ONLY",
    "ç–‘ä¼¼": "SUSPECTED_ONLY",
    "æ— å¼‚å¸¸": "NO_ABNORMALITY",
    "æ­£å¸¸": "NO_ABNORMALITY",
}

BIRD_INFO_MAP = {
    "å¤§å‹é¸Ÿ": "LARGE_BIRD",
    "å¤§é¸Ÿ": "LARGE_BIRD",
    "é¸Ÿç¾¤": "FLOCK",
    "ç¾¤é¸Ÿ": "FLOCK",
    "ä¸­å°å‹": "MEDIUM_SMALL_SINGLE",
    "å°å‹": "MEDIUM_SMALL_SINGLE",
    "å•åª": "MEDIUM_SMALL_SINGLE",
    "ä¸æ˜": "UNKNOWN",
    "æœªçŸ¥": "UNKNOWN",
}

OPS_IMPACT_MAP = {
    "ä¸­æ–­èµ·é£": "RTO_OR_RTB",
    "è¿”èˆª": "RTO_OR_RTB",
    "å¤‡é™": "RTO_OR_RTB",
    "å ç”¨è·‘é“": "BLOCKING_RUNWAY_OR_TAXIWAY",
    "å ç”¨æ»‘è¡Œé“": "BLOCKING_RUNWAY_OR_TAXIWAY",
    "é˜»å¡è·‘é“": "BLOCKING_RUNWAY_OR_TAXIWAY",
    "é˜»å¡æ»‘è¡Œé“": "BLOCKING_RUNWAY_OR_TAXIWAY",
    "æœºåŠ¡æ£€æŸ¥": "REQUEST_MAINT_CHECK",
    "è¯·æ±‚æ£€æŸ¥": "REQUEST_MAINT_CHECK",
    "å¾…æ£€æŸ¥": "REQUEST_MAINT_CHECK",
    "ä¸å½±å“è¿è¡Œ": "NO_OPS_IMPACT",
    "æ— å½±å“": "NO_OPS_IMPACT",
    "ä¸æ˜": "UNKNOWN",
    "æœªçŸ¥": "UNKNOWN",
}


def _merge_patterns(scenario_type: str) -> Dict[str, Any]:
    """åˆå¹¶é€šç”¨æ­£åˆ™ä¸åœºæ™¯æ­£åˆ™ï¼ˆmanifest regexï¼‰"""
    base = {k: v[:] if isinstance(v, list) else v for k, v in BASE_PATTERNS.items()}
    scenario = ScenarioRegistry.get(scenario_type) if scenario_type else None
    if scenario and scenario.regex_patterns:
        for key, items in scenario.regex_patterns.items():
            merged: List[Any] = []
            for item in items or []:
                pattern = item.get("pattern")
                value = item.get("value")
                if pattern:
                    merged.append((pattern, value))
            if merged:
                base[key] = merged
    return base


def extract_entities(text: str, scenario_type: Optional[str] = None) -> Dict[str, Any]:
    """ä»æ–‡æœ¬ä¸­æå–å®ä½“ï¼ˆé€šç”¨+åœºæ™¯ regexï¼‰"""
    entities: Dict[str, Any] = {}
    patterns = _merge_patterns(scenario_type or "")

    for pattern in patterns.get("position", []):
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            if len(match.groups()) == 2:
                prefix, suffix = match.group(1), match.group(2)
                entities["position"] = f"{prefix}{suffix}"
            else:
                entities["position"] = match.group(1)
            break

    if "position" not in entities:
        text_stripped = text.strip()
        if re.match(r"^\d{2,3}$", text_stripped):
            entities["position"] = text_stripped
        elif re.match(r"^(è·‘é“|æ»‘è¡Œé“|æœºä½)\s*\d+", text_stripped, re.IGNORECASE):
            match = re.match(r"^(è·‘é“|æ»‘è¡Œé“|æœºä½)\s*(\d+)", text_stripped, re.IGNORECASE)
            if match:
                entities["position"] = f"{match.group(1)}{match.group(2)}"
        else:
            match = re.search(r"(è·‘é“|æ»‘è¡Œé“|æœºä½|TWY|RWY)[_\s]?([A-Z]?\d+)", text, re.IGNORECASE)
            if match:
                entities["position"] = f"{match.group(1)}{match.group(2)}"
            else:
                match = re.search(r"\b(\d{2,3})\b", text)
                if match:
                    entities["position"] = match.group(1)

    for pattern, value in patterns.get("fluid_type", []):
        if re.search(pattern, text):
            entities["fluid_type"] = value
            break

    for key in ["event_type", "affected_part", "current_status", "crew_request"]:
        for pattern, value in patterns.get(key, []):
            if re.search(pattern, text):
                entities[key] = value
                break

    for pattern, value in patterns.get("engine_status", []):
        if re.search(pattern, text):
            entities["engine_status"] = value
            break

    for pattern, value in patterns.get("continuous", []):
        if re.search(pattern, text):
            entities["continuous"] = value
            break

    for pattern, value in patterns.get("leak_size", []):
        if re.search(pattern, text):
            entities["leak_size"] = value
            break

    for pattern in patterns.get("aircraft", []):
        match = re.search(pattern, text)
        if match:
            value = match.group(1)
            if value.startswith("B-"):
                continue
            elif value.isdigit():
                for cn_name, code in AIRLINE_CHINESE_TO_IATA.items():
                    if cn_name in text:
                        entities["flight_no_display"] = f"{cn_name}{value}"
                        entities["flight_no"] = f"{code}{value}"
                        break
            else:
                entities["flight_no_display"] = value
                entities["flight_no"] = value
            break

    return entities


def extract_entities_llm(text: str, history: str = "") -> Dict[str, Any]:
    """ä½¿ç”¨ LLM æå–å®ä½“ï¼ˆæ›´çµæ´»ï¼‰"""
    try:
        llm = get_llm_client()
        prompt = LLM_EXTRACT_PROMPT.format(history=history, user_input=text)
        response = llm.invoke(prompt)
        content = response.content if hasattr(response, 'content') else str(response)

        # è§£æ JSON
        import json
        entities = json.loads(content)

        # ç¿»è¯‘ä¸­æ–‡å€¼ä¸ºä»£ç å€¼
        if "fluid_type" in entities and entities["fluid_type"]:
            ft = str(entities["fluid_type"]).upper()
            entities["fluid_type"] = POS_TYPE_MAP.get(ft, ft) if ft not in ["FUEL", "HYDRAULIC", "OIL", "UNKNOWN", "NULL", None] else ft

        if "engine_status" in entities and entities["engine_status"]:
            es = str(entities["engine_status"]).upper()
            entities["engine_status"] = ENG_TYPE_MAP.get(es, es) if es not in ["RUNNING", "STOPPED", "UNKNOWN", "NULL", None] else es

        if "leak_size" in entities and entities["leak_size"]:
            ls = str(entities["leak_size"]).upper()
            # å¦‚æœæ˜¯ä¸­æ–‡è¡¨è¾¾ï¼Œå°è¯•æ˜ å°„ï¼›å¦‚æœå·²ç»æ˜¯æ ‡å‡†å€¼ï¼Œä¿æŒä¸å˜
            if ls not in ["LARGE", "MEDIUM", "SMALL", "UNKNOWN", "NULL"]:
                entities["leak_size"] = SIZE_TYPE_MAP.get(ls, ls)
            else:
                entities["leak_size"] = ls

        if "phase" in entities and entities["phase"]:
            phase = str(entities["phase"]).upper()
            if phase not in [
                "PUSHBACK", "TAXI", "TAKEOFF_ROLL", "INITIAL_CLIMB", "CRUISE",
                "DESCENT", "APPROACH", "LANDING_ROLL", "ON_STAND", "UNKNOWN",
            ]:
                entities["phase"] = PHASE_TYPE_MAP.get(phase, phase)
            else:
                entities["phase"] = phase

        if "evidence" in entities and entities["evidence"]:
            evidence = str(entities["evidence"]).upper()
            if evidence not in [
                "CONFIRMED_STRIKE_WITH_REMAINS",
                "SYSTEM_WARNING",
                "ABNORMAL_NOISE_VIBRATION",
                "SUSPECTED_ONLY",
                "NO_ABNORMALITY",
                "UNKNOWN",
            ]:
                entities["evidence"] = EVIDENCE_TYPE_MAP.get(evidence, evidence)
            else:
                entities["evidence"] = evidence

        if "bird_info" in entities and entities["bird_info"]:
            bird_info = str(entities["bird_info"]).upper()
            if bird_info not in ["LARGE_BIRD", "FLOCK", "MEDIUM_SMALL_SINGLE", "UNKNOWN"]:
                entities["bird_info"] = BIRD_INFO_MAP.get(bird_info, bird_info)
            else:
                entities["bird_info"] = bird_info

        if "ops_impact" in entities and entities["ops_impact"]:
            ops_impact = str(entities["ops_impact"]).upper()
            if ops_impact not in [
                "RTO_OR_RTB",
                "BLOCKING_RUNWAY_OR_TAXIWAY",
                "REQUEST_MAINT_CHECK",
                "NO_OPS_IMPACT",
                "UNKNOWN",
            ]:
                entities["ops_impact"] = OPS_IMPACT_MAP.get(ops_impact, ops_impact)
            else:
                entities["ops_impact"] = ops_impact

        # æ¸…ç† null å€¼
        return {k: v for k, v in entities.items() if v not in [None, "null", "NULL", ""]}

    except Exception:
        return {}


def extract_entities_hybrid(text: str, history: str = "", scenario_type: Optional[str] = None) -> Dict[str, Any]:
    """
    æ··åˆå®ä½“æå–ï¼šå…ˆç”¨æ­£åˆ™ï¼Œå†ç”¨ LLM è¡¥å……

    ç­–ç•¥ï¼š
    1. å¿«é€Ÿè·¯å¾„ï¼šæ­£åˆ™æå–ï¼ˆå¤„ç†æ ¼å¼å›ºå®šçš„ï¼šèˆªç­å·ã€ä½ç½®ï¼‰
    2. çµæ´»è·¯å¾„ï¼šLLM æå–ï¼ˆå¤„ç†è¯­ä¹‰è¡¨è¾¾ï¼‰
    """
    # ç¬¬ä¸€æ­¥ï¼šæ­£åˆ™æå–ï¼ˆå¿«é€Ÿã€ç¡®å®šæ€§ï¼‰
    entities = extract_entities(text, scenario_type)

    # ç¬¬äºŒæ­¥ï¼šLLM è¡¥å……ï¼ˆå¤„ç†æ¨¡ç³Šè¡¨è¾¾ï¼‰
    llm_entities = extract_entities_llm(text, history)

    # åˆå¹¶ç»“æœï¼šLLM ç»“æœè¦†ç›–æ­£åˆ™ç»“æœï¼ˆæ›´æ™ºèƒ½ï¼‰
    for key, value in llm_entities.items():
        # å¦‚æœ LLM æå–äº†æ­£åˆ™æ²¡æå–åˆ°çš„ï¼Œæˆ–è€… LLM æ˜ç¡®è¯´äº†æŸä¸ªå€¼
        if key not in entities or (value is not None and value != "null"):
            entities[key] = value

    return entities


# å¦‚æœç›´æ¥è¿è¡Œï¼Œæµ‹è¯•æå–æ•ˆæœ
if __name__ == "__main__":
    test_inputs = [
        "501æœºä½å‘ç°ç‡ƒæ²¹æ³„æ¼ï¼Œå‘åŠ¨æœºè¿è½¬ä¸­ï¼ŒæŒç»­æ»´æ¼ï¼Œé¢ç§¯å¤§æ¦‚2å¹³ç±³",
        "A3æ»‘è¡Œé“æœ‰æ¶²å‹æ²¹æ¼",
        "CA1234èˆªç­åœ¨32å·æœºä½ï¼Œå‘åŠ¨æœºå·²å…³é—­",
        "è·‘é“01Lå‘ç°ä¸æ˜æ²¹æ¶²",
        "CA2345ï¼Œæ»‘è¡Œé“234ï¼ŒæŠ¥å‘Šæ¼æ²¹",  # æµ‹è¯•å¤šå®ä½“æå–
    ]

    print("=" * 60)
    print("æµ‹è¯•å¤šå®ä½“æå–")
    print("=" * 60)

    for inp in test_inputs:
        print(f"\nè¾“å…¥: {inp}")
        print(f"æ­£åˆ™: {extract_entities(inp)}")
        print(f"æ··åˆ: {extract_entities_hybrid(inp)}")
def _infer_required_fields(scenario: Any, incident: Dict[str, Any]) -> List[str]:
    """æ ¹æ®åœºæ™¯æˆ–å·²æœ‰å­—æ®µæ¨æ–­å¿…å¡«å­—æ®µåˆ—è¡¨ï¼Œé¿å…è¯¯ç”¨æ¼æ²¹å­—æ®µã€‚"""
    if scenario:
        return [
            field.get("key")
            for field in scenario.p1_fields
            if field.get("key") and field.get("required", True)
        ]
    # æ— åœºæ™¯ä½†å·²æœ‰é¸Ÿå‡»å­—æ®µæ—¶ï¼ŒæŒ‰é¸Ÿå‡»å¿…å¡«
    bird_keys = {"event_type", "affected_part", "current_status", "crew_request"}
    if bird_keys.intersection(incident.keys()):
        return ["flight_no", "position", "event_type", "affected_part", "current_status", "crew_request"]
    return ["fluid_type", "position", "engine_status", "continuous", "flight_no"]


def _select_scenario(current: str, detected: str) -> str:
    """æ ¹æ®ä¼˜å…ˆçº§é€‰æ‹©åœºæ™¯ï¼Œé¿å…å·²ç¡®è®¤åœºæ™¯è¢«é™çº§ã€‚"""
    if not current:
        return detected
    if current == detected:
        return current

    current_scenario = ScenarioRegistry.get(current)
    detected_scenario = ScenarioRegistry.get(detected)
    cur_priority = current_scenario.metadata.get("priority", 100) if current_scenario else 100
    det_priority = detected_scenario.metadata.get("priority", 100) if detected_scenario else 100

    # ä¼˜å…ˆä¿ç•™æ›´é«˜ä¼˜å…ˆçº§ï¼ˆæ•°å€¼æ›´å°ï¼‰çš„åœºæ™¯ï¼Œé¿å…ä»é¸Ÿå‡»åˆ‡å›æ¼æ²¹
    if cur_priority <= det_priority:
        return current
    return detected
