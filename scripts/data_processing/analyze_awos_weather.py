#!/usr/bin/env python3
"""
AWOSæ°”è±¡æ•°æ®åˆ†æè„šæœ¬

å¯¹æå–çš„æ°”è±¡æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æï¼Œç”ŸæˆæŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/data_processing/analyze_awos_weather.py

è¾“å‡º:
    - data/processed/awos_analysis_report.txt: æ–‡æœ¬åˆ†ææŠ¥å‘Š
    - data/processed/awos_per_location/: æŒ‰ä½ç½®åˆ†ç¦»çš„CSVæ–‡ä»¶
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import Dict, List
import json


def load_weather_data(csv_path: Path) -> pd.DataFrame:
    """åŠ è½½æ°”è±¡æ•°æ®CSV"""
    df = pd.read_csv(csv_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    return df


def generate_statistics(df: pd.DataFrame, field: str) -> Dict:
    """ç”Ÿæˆå•ä¸ªå­—æ®µçš„ç»Ÿè®¡ä¿¡æ¯"""
    series = df[field].dropna()

    if len(series) == 0:
        return {
            'count': 0,
            'missing': len(df),
            'missing_pct': 100.0
        }

    return {
        'count': len(series),
        'missing': df[field].isna().sum(),
        'missing_pct': (df[field].isna().sum() / len(df)) * 100,
        'min': float(series.min()) if series.dtype in ['float64', 'int64'] else None,
        'max': float(series.max()) if series.dtype in ['float64', 'int64'] else None,
        'mean': float(series.mean()) if series.dtype in ['float64', 'int64'] else None,
        'std': float(series.std()) if series.dtype in ['float64', 'int64'] else None,
    }


def generate_location_report(df: pd.DataFrame, location_id: str) -> str:
    """ç”Ÿæˆå•ä¸ªä½ç½®çš„æŠ¥å‘Š"""
    df_loc = df[df['location_id'] == location_id]

    if len(df_loc) == 0:
        return f"\n## ä½ç½® {location_id}: æ— æ•°æ®\n"

    report = f"\n## ä½ç½® {location_id}\n"
    report += f"  æ•°æ®è®°å½•æ•°: {len(df_loc)}\n"
    report += f"  æ—¶é—´èŒƒå›´: {df_loc['timestamp'].min()} ~ {df_loc['timestamp'].max()}\n"
    report += f"  æ—¶é—´è·¨åº¦: {(df_loc['timestamp'].max() - df_loc['timestamp'].min()).total_seconds() / 3600:.1f} å°æ—¶\n\n"

    # ç»Ÿè®¡å„å­—æ®µ
    fields_to_analyze = [
        ('æ¸©åº¦ (Â°C)', 'temperature'),
        ('éœ²ç‚¹ (Â°C)', 'dew_point'),
        ('ç›¸å¯¹æ¹¿åº¦ (%)', 'relative_humidity'),
        ('èƒ½è§åº¦ (m)', 'visibility'),
        ('RVR (m)', 'rvr'),
        ('QNH (hPa)', 'qnh'),
        ('QFE (hPa)', 'qfe'),
        ('ç«™å‹ (hPa)', 'station_pressure'),
        ('é£å‘ (åº¦)', 'wind_direction'),
        ('é£é€Ÿ (m/s)', 'wind_speed'),
        ('10ç±³é£å‘ (åº¦)', 'wind_direction_10m'),
        ('10ç±³é£é€Ÿ (m/s)', 'wind_speed_10m'),
        ('2ç±³é£å‘ (åº¦)', 'wind_direction_2m'),
        ('2ç±³é£é€Ÿ (m/s)', 'wind_speed_2m'),
        ('æ¨ªé£åˆ†é‡ (m/s)', 'cross_wind_2a'),
        ('é¡¶é£åˆ†é‡ (m/s)', 'head_wind_2a'),
    ]

    report += "  å­—æ®µç»Ÿè®¡:\n"
    for label, field in fields_to_analyze:
        if field in df_loc.columns:
            stats = generate_statistics(df_loc, field)
            if stats['count'] > 0 and stats['mean'] is not None:
                report += f"    {label:20s}: {stats['count']:4d} æ¡è®°å½•, "
                report += f"èŒƒå›´ [{stats['min']:.1f}, {stats['max']:.1f}], "
                report += f"å¹³å‡ {stats['mean']:.1f}Â±{stats['std']:.1f}, "
                report += f"ç¼ºå¤±ç‡ {stats['missing_pct']:.1f}%\n"
            else:
                report += f"    {label:20s}: {stats['count']:4d} æ¡è®°å½•, "
                report += f"ç¼ºå¤±ç‡ {stats['missing_pct']:.1f}%\n"

    return report


def split_by_location(df: pd.DataFrame, output_dir: Path) -> None:
    """æŒ‰ä½ç½®åˆ†ç¦»æ•°æ®å¹¶ä¿å­˜ä¸ºç‹¬ç«‹CSVæ–‡ä»¶"""
    loc_dir = output_dir / 'awos_per_location'
    loc_dir.mkdir(parents=True, exist_ok=True)

    locations = sorted(df['location_id'].unique())

    print(f"\nğŸ“ æŒ‰ä½ç½®åˆ†ç¦»æ•°æ®...")

    for location_id in locations:
        df_loc = df[df['location_id'] == location_id]
        output_file = loc_dir / f"awos_{location_id}.csv"
        df_loc.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"   âœ… {location_id}: {len(df_loc)} æ¡è®°å½• -> {output_file.name}")


def generate_summary_report(df: pd.DataFrame) -> str:
    """ç”Ÿæˆæ€»ä½“ç»Ÿè®¡æŠ¥å‘Š"""
    report = "=" * 80 + "\n"
    report += "AWOSæ°”è±¡æ•°æ®åˆ†ææŠ¥å‘Š\n"
    report += "=" * 80 + "\n\n"

    report += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
    report += f"æ•°æ®æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}\n"
    report += f"æ€»è®°å½•æ•°: {len(df)}\n"
    report += f"ä½ç½®æ•°é‡: {df['location_id'].nunique()}\n"
    report += f"ä½ç½®åˆ—è¡¨: {', '.join(sorted(df['location_id'].unique()))}\n\n"

    # æ€»ä½“ç»Ÿè®¡
    report += "## æ€»ä½“å­—æ®µç»Ÿè®¡\n\n"

    fields_to_analyze = [
        ('temperature', 'æ¸©åº¦ (Â°C)'),
        ('dew_point', 'éœ²ç‚¹ (Â°C)'),
        ('relative_humidity', 'ç›¸å¯¹æ¹¿åº¦ (%)'),
        ('visibility', 'èƒ½è§åº¦ (m)'),
        ('rvr', 'RVR (m)'),
        ('qnh', 'QNH (hPa)'),
        ('qfe', 'QFE (hPa)'),
        ('station_pressure', 'ç«™å‹ (hPa)'),
        ('wind_direction', 'é£å‘ (åº¦)'),
        ('wind_speed', 'é£é€Ÿ (m/s)'),
        ('wind_direction_10m', '10ç±³é£å‘ (åº¦)'),
        ('wind_speed_10m', '10ç±³é£é€Ÿ (m/s)'),
        ('wind_direction_2m', '2ç±³é£å‘ (åº¦)'),
        ('wind_speed_2m', '2ç±³é£é€Ÿ (m/s)'),
        ('cross_wind_2a', 'æ¨ªé£åˆ†é‡ (m/s)'),
        ('head_wind_2a', 'é¡¶é£åˆ†é‡ (m/s)'),
    ]

    for field, label in fields_to_analyze:
        if field in df.columns:
            stats = generate_statistics(df, field)
            report += f"{label:20s}: "
            report += f"æœ‰æ•ˆ {stats['count']:4d}/{len(df):4d} ({100-stats['missing_pct']:5.1f}%), "
            if stats['mean'] is not None:
                report += f"èŒƒå›´ [{stats['min']:7.1f}, {stats['max']:7.1f}], "
                report += f"å¹³å‡ {stats['mean']:7.1f}Â±{stats['std']:5.1f}\n"
            else:
                report += "\n"

    report += "\n"

    # æŒ‰ä½ç½®ç»Ÿè®¡
    report += "## æŒ‰ä½ç½®è¯¦ç»†ç»Ÿè®¡\n"
    for location_id in sorted(df['location_id'].unique()):
        report += generate_location_report(df, location_id)

    return report


def detect_data_quality_issues(df: pd.DataFrame) -> List[str]:
    """æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜"""
    issues = []

    # æ£€æŸ¥1: æ¸©åº¦å¼‚å¸¸å€¼
    if 'temperature' in df.columns:
        temp_extreme = df[(df['temperature'] < -50) | (df['temperature'] > 50)]
        if len(temp_extreme) > 0:
            issues.append(f"âš ï¸  å‘ç° {len(temp_extreme)} æ¡æ¸©åº¦å¼‚å¸¸å€¼è®°å½•ï¼ˆ<-50Â°Cæˆ–>50Â°Cï¼‰")

    # æ£€æŸ¥2: é£é€Ÿå¼‚å¸¸å€¼
    if 'wind_speed' in df.columns:
        wind_extreme = df[df['wind_speed'] > 50]
        if len(wind_extreme) > 0:
            issues.append(f"âš ï¸  å‘ç° {len(wind_extreme)} æ¡é£é€Ÿå¼‚å¸¸å€¼è®°å½•ï¼ˆ>50 m/sï¼‰")

    # æ£€æŸ¥3: ç›¸å¯¹æ¹¿åº¦è¶…å‡ºèŒƒå›´
    if 'relative_humidity' in df.columns:
        rh_invalid = df[(df['relative_humidity'] < 0) | (df['relative_humidity'] > 100)]
        if len(rh_invalid) > 0:
            issues.append(f"âš ï¸  å‘ç° {len(rh_invalid)} æ¡ç›¸å¯¹æ¹¿åº¦æ— æ•ˆè®°å½•ï¼ˆ<0%æˆ–>100%ï¼‰")

    # æ£€æŸ¥4: æ°”å‹å¼‚å¸¸å€¼
    if 'qnh' in df.columns:
        qnh_extreme = df[(df['qnh'] < 800) | (df['qnh'] > 1100)]
        if len(qnh_extreme) > 0:
            issues.append(f"âš ï¸  å‘ç° {len(qnh_extreme)} æ¡QNHæ°”å‹å¼‚å¸¸å€¼è®°å½•ï¼ˆ<800 hPaæˆ–>1100 hPaï¼‰")

    return issues


def main():
    """ä¸»å‡½æ•°"""
    base_dir = Path(__file__).parent.parent.parent
    processed_dir = base_dir / 'data' / 'processed'

    # æŸ¥æ‰¾æœ€æ–°çš„æ°”è±¡æ•°æ®CSV
    csv_files = sorted(processed_dir.glob('awos_weather_*.csv'))
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°å¤„ç†åçš„æ°”è±¡æ•°æ®CSVæ–‡ä»¶")
        print("   è¯·å…ˆè¿è¡Œ extract_awos_weather.py ç”Ÿæˆæ•°æ®")
        return

    csv_path = csv_files[-1]  # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶

    print("=" * 80)
    print("ğŸ“Š AWOSæ°”è±¡æ•°æ®åˆ†æå·¥å…·")
    print("=" * 80)
    print()
    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {csv_path.name}")

    # åŠ è½½æ•°æ®
    df = load_weather_data(csv_path)

    print(f"   âœ… æ€»è®¡ {len(df)} æ¡è®°å½•")
    print(f"   âœ… {df['location_id'].nunique()} ä¸ªä½ç½®")
    print(f"   âœ… æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")

    # æ£€æµ‹æ•°æ®è´¨é‡é—®é¢˜
    print("\nğŸ” æ£€æµ‹æ•°æ®è´¨é‡...")
    issues = detect_data_quality_issues(df)
    if issues:
        for issue in issues:
            print(f"   {issue}")
    else:
        print("   âœ… æœªå‘ç°æ˜æ˜¾æ•°æ®è´¨é‡é—®é¢˜")

    # æŒ‰ä½ç½®åˆ†ç¦»æ•°æ®
    split_by_location(df, processed_dir)

    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    report = generate_summary_report(df)

    # ä¿å­˜æŠ¥å‘Š
    report_file = processed_dir / f"awos_analysis_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"   âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file.name}")

    # æ‰“å°æŠ¥å‘Šæ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“‹ åˆ†ææŠ¥å‘Šæ‘˜è¦")
    print("=" * 80)
    print(report[:2000])  # æ‰“å°å‰2000ä¸ªå­—ç¬¦
    print("...")
    print("\nå®Œæ•´æŠ¥å‘Šè¯·æŸ¥çœ‹: " + report_file.name)
    print("=" * 80)


if __name__ == '__main__':
    main()
